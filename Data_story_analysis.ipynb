{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579d5f83-5f2b-4c66-88d9-b431f81fc88e",
   "metadata": {},
   "source": [
    "**This is the final notebook for Milestone 3, where all the data analysis (besides the pre processing done in Milestone 2) is done.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "3bf194e9-851f-4f7d-b8df-0d92cc8ecde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (5.4.0)\n",
      "Requirement already satisfied: six in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from plotly) (1.16.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from plotly) (8.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f9869f0-3c97-41a8-9607-7e687124bec3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.9 MB 13.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from en-core-web-sm==3.2.0) (3.2.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.26.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.21.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: setuptools in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (58.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.5)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: jinja2 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/charneca/opt/anaconda3/lib/python3.9/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import timeit\n",
    "import bz2\n",
    "import datetime\n",
    "import sys\n",
    "from empath import Empath\n",
    "import json\n",
    "#from src.prep_utilities import * \n",
    "#from src.prep_pipeline import *\n",
    "\n",
    "# Load nltk models\n",
    "#!python ./src/load_models_data.py\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "!python ./src/load_models_data.py\n",
    "data_folder = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d4b783-5da9-4b16-9509-02f235c96892",
   "metadata": {},
   "source": [
    "# General Gender Bias Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9303118b-78e0-4843-a49d-a32d742ee8c5",
   "metadata": {},
   "source": [
    "In this section, we plan to analyse:\n",
    " - Evolution of percentage of speakers by gender, over time\n",
    " - Evolution of percentage of quotations by gender, over time\n",
    " - Most quoted speakers by gender, over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dfe526-ce0b-46a1-a259-81af57e00d63",
   "metadata": {},
   "source": [
    "We'll do a month-by-month analysis. For each month/gender combination, we'll save a Dataframe with the speakers and their total number of quotations that month.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb66d116-43d5-48a7-9b61-18e0caa774b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time ranges\n",
    "years = range(2015,2021)\n",
    "min_month = \"2015-01\"\n",
    "max_month = \"2020-04\"\n",
    "all_months = pd.period_range(min_month, max_month, freq='M')\n",
    "\n",
    "genders = ['male', 'female', 'transgender male', 'transgender female', 'non-binary', 'genderfluid']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "595d55ad-2d98-4273-846c-7ed0f62656ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numOccurrences</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speaker</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [numOccurrences]\n",
       "Index: []"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dictionaries we'll use to store analysis\n",
    "\n",
    "speaker_df = {} # Save the dataframes of top speakers by gender/month\n",
    "\n",
    "for gender in genders:  \n",
    "    speakers_df_temp = {}\n",
    "    \n",
    "    for month in all_months:\n",
    "\n",
    "        speakers_df_temp[month] = pd.DataFrame([], columns = ['speaker', 'numOccurrences']).set_index('speaker')\n",
    "\n",
    "    speaker_df[gender] = speakers_df_temp\n",
    "    \n",
    "speaker_df['male'][all_months[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9410e3e-bef4-49b8-a2d9-efe7de556318",
   "metadata": {},
   "source": [
    "The pre-processed data will be loaded each year, by chunks. In the analyses, we will cycle through each year, and through each chunk, and save the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "318cc39e-f9f2-4227-a606-b6d1821e93b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing year 2015... Done in 1503.41s\n",
      "Analysing year 2016... Done in 878.96s\n",
      "Analysing year 2017... Done in 2293.26s\n",
      "Analysing year 2018... Done in 2267.08s\n",
      "Analysing year 2019... Done in 1588.40s\n",
      "Analysing year 2020... Done in 179.75s\n"
     ]
    }
   ],
   "source": [
    "# Loop through years\n",
    "for year in years:\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    # data location and chunk size\n",
    "    data_file = 'quotes-'+ str(year)+'-prep.json.bz2'\n",
    "    data_path = data_folder + data_file\n",
    "    chunk_size = 1e4\n",
    "\n",
    "    # Load by chunks\n",
    "    f = bz2.open(data_path, \"rb\")\n",
    "    data=pd.read_json(f, lines=True, chunksize=chunk_size)\n",
    "    \n",
    "    print(f\"Analysing year {year}...\", end=\" \")\n",
    "    \n",
    "\n",
    "    # Loop through chunks\n",
    "    for i_chunk, chunk in enumerate(data):\n",
    "        \n",
    "        ## Run analysis ##\n",
    "        \n",
    "        # Create range of months for this year\n",
    "        if year != 2020:\n",
    "            months = pd.period_range(str(year)+'-'+'01', str(year)+'-'+'12', freq='M')\n",
    "        else:\n",
    "            months = pd.period_range(str(year)+'-'+'01', str(year)+'-'+'04', freq='M')\n",
    "\n",
    "        # Loop through months\n",
    "        for month in months:\n",
    "            # Mask to select desired month\n",
    "            month_mask = (chunk['date'].dt.to_period('m') == month)\n",
    "            \n",
    "            # Loop through genders\n",
    "            for gender in genders:\n",
    "                \n",
    "                # Mask to select desired gender\n",
    "                gender_mask = (chunk['gender'] == gender)\n",
    "                \n",
    "                # Concatenate the speakers in this chunk with our dictionary\n",
    "                df = chunk[gender_mask & month_mask].groupby(\"speaker\").sum()\n",
    "                speaker_df[gender][month] = pd.concat([speaker_df[gender][month],df]).groupby(\"speaker\").sum()\n",
    "\n",
    "    stop = timeit.default_timer()\n",
    "    print(f\"Done in {stop-start:.2f}s\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "60b744ec-e474-4b63-9dac-fad2997beb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numOccurrences</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speaker</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Natalie Cole</th>\n",
       "      <td>3318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cheryl Boone Isaacs</th>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clover Moore</th>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jane Mayer</th>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gillian Armstrong</th>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cecilia Rodriguez</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mona Chalabi</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mona Charen</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Catherine Zeta-Jones</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Katherine Klein</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1745 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      numOccurrences\n",
       "speaker                             \n",
       "Natalie Cole                    3318\n",
       "Cheryl Boone Isaacs              435\n",
       "Clover Moore                     325\n",
       "Jane Mayer                       276\n",
       "Gillian Armstrong                267\n",
       "...                              ...\n",
       "Cecilia Rodriguez                  1\n",
       "Mona Chalabi                       1\n",
       "Mona Charen                        1\n",
       "Catherine Zeta-Jones               1\n",
       "Katherine Klein                    1\n",
       "\n",
       "[1745 rows x 1 columns]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_df['female'][all_months[12]].sort_values(by='numOccurrences', ascending = False)\n",
    "#speaker_df['male'][all_months[0]].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227a8e76-f638-4cd4-8cf6-004d20d50a2d",
   "metadata": {},
   "source": [
    "Since we don't want to run the previous cell everytime we reload the notebook, we'll save each of the gender/month combinations to a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "96efe899-da28-4dee-8879-76aa0d5406ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_analysis_folder = data_folder + '/general_analysis/'\n",
    "\n",
    "for gender in genders:\n",
    "    for month in all_months:\n",
    "        with bz2.open(general_analysis_folder + gender +'-' + str(month.year) + '-' + str(month.month) + '.json.bz2', \"w\") as f:\n",
    "\n",
    "            # Write to file, reset index to keep the speaker's names\n",
    "            write = speaker_df[gender][month].reset_index().to_json(f, lines=True, orient='records') \n",
    "### 2015,16,17 done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5167305f-0efc-434f-a566-7016fe3a9b39",
   "metadata": {},
   "source": [
    "Now that we've created the files with the analysis data, let's read them again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c421df4-17b9-46d6-b13d-aa58cc34f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_df = {} # Load the dataframes of top speakers by gender/month\n",
    "general_analysis_folder = data_folder + '/general_analysis/'\n",
    "\n",
    "for gender in genders:  \n",
    "    speakers_df_temp = {}\n",
    "    \n",
    "    for month in all_months:\n",
    "        speakers_df_temp[month] = pd.read_json(general_analysis_folder + gender +'-' + str(month.year) + '-' + str(month.month) + '.json.bz2', lines = True,compression = 'bz2')\n",
    "        \n",
    "        # Join rows of presidential aliases (President Trump, Donald Trump, etc...)\n",
    "        speakers_df_temp[month] = speakers_df_temp[month].replace([\"President Barack Obama\", \"President Obama\"], \"Barack Obama\")\n",
    "        speakers_df_temp[month] = speakers_df_temp[month].replace([\"President Donald Trump\", \"President Trump\"], \"Donald Trump\")\n",
    "        speakers_df_temp[month] = speakers_df_temp[month].groupby('speaker').sum().reset_index()\n",
    "\n",
    "    speaker_df[gender] = speakers_df_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a6514a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST\n",
    "speaker, num = speaker_df['female'][all_months[0]].sort_values(by='numOccurrences', ascending = False).iloc[0]\n",
    "\n",
    "#speaker_df['male'][all_months[0]][speaker_df['male'][all_months[0]]['speaker'].isin(['President Barack Obama', 'President Obama'])].sum()\n",
    "#speaker_df['male'][all_months[0]].replace([\"President Barack Obama\", \"President Obama\"], \"Barack Obama\").groupby('speaker').sum().sort_values(by='numOccurrences', ascending = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f3df3b-023d-423b-8776-92465630fb02",
   "metadata": {},
   "source": [
    "## Plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07593b46",
   "metadata": {},
   "source": [
    "### Percentage of quotations and speakers by gender\n",
    "\n",
    "We will use the package `plotly` to make an interactive plot with our data in the cells below.\n",
    "\n",
    "To view the plot, double click `plotly/general_quotations_speakers.html`.\n",
    "\n",
    "First, we create DataFrames to hold the plot data, and then we plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d78614a-4a87-4ad1-9ea8-496f23c81615",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare data to be plotted ##\n",
    "\n",
    "# x data\n",
    "month_str = [str(month.year)+'-'+str(month.month) for month in all_months]\n",
    "month_dt = [datetime.datetime.strptime(x, '%Y-%m') for x in month_str]\n",
    "\n",
    "# y data\n",
    "total_quotations = {} # total quotations by month\n",
    "total_speakers = {} # total number of speakers by month\n",
    "\n",
    "for month in all_months:\n",
    "    total_quotations[month] = 0\n",
    "    total_speakers[month] = 0\n",
    "\n",
    "    for gender in genders:\n",
    "        total_quotations[month] += speaker_df[gender][month]['numOccurrences'].sum()\n",
    "        total_speakers[month] += len(speaker_df[gender][month])\n",
    "\n",
    "perc_quotations = pd.DataFrame([], columns = genders) # df with the dates and percentage of quotations by gender\n",
    "perc_speakers =  pd.DataFrame([], columns = genders) # df with the dates and percentage of speakers by gender\n",
    "\n",
    "for i,month in enumerate(all_months):\n",
    "    perc_quotations.loc[i] = [100*speaker_df[gender][month]['numOccurrences'].sum()/total_quotations[month] for gender in genders]\n",
    "    perc_speakers.loc[i] = [100*len(speaker_df[gender][month])/total_speakers[month] for gender in genders]\n",
    "    \n",
    "perc_quotations['date'] = month_dt # Dates for x axis\n",
    "perc_speakers['date'] = month_dt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3c4b11",
   "metadata": {},
   "source": [
    "Run the cell below to generate the \"Percentage of Quotations by Gender\" plot. Double click `plotly/perc_quotations.html` to view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "412584b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Color palette\n",
    "palette = px.colors.qualitative.Plotly\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "fig.update_layout(title = 'Percentage of Quotations by Gender')\n",
    "fig.update_xaxes(title='Date')\n",
    "fig.update_yaxes(title='Percentage of Quotations')\n",
    "\n",
    "# Add plots (they have to be added by order, in order not to mess up the 'visible' lists)\n",
    "for i,gender in enumerate(genders):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x = perc_quotations['date'], y = perc_quotations[gender], name = gender, mode='lines', line=dict(color=palette[i], width=3))\n",
    "        )\n",
    "\n",
    "\n",
    "visible_quotations = [True if i<6 else False for i in range(12)]\n",
    "visible_speakers = [not x for x in visible_quotations]\n",
    "\n",
    "# Add x range slider\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        rangeslider=dict(\n",
    "            visible=True\n",
    "        ),\n",
    "        type=\"date\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.write_html(\"plotly/perc_quotations.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4a084b",
   "metadata": {},
   "source": [
    "Run the cell below to generate the \"Percentage of Speakers by Gender\" plot. Double click `plotly/perc_speakers.html` to view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d97c12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Color palette\n",
    "palette = px.colors.qualitative.Plotly\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "fig.update_layout(title = 'Percentage of Speakers by Gender')\n",
    "fig.update_xaxes(title='Date')\n",
    "fig.update_yaxes(title='Percentage of Speakers')\n",
    "\n",
    "# Add plots\n",
    "for i,gender in enumerate(genders):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x = perc_speakers['date'], y = perc_speakers[gender], name = gender, mode='lines', line=dict(color=palette[i], width=3))\n",
    "        )\n",
    "\n",
    "# Add x range slider\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        rangeslider=dict(\n",
    "            visible=True\n",
    "        ),\n",
    "        type=\"date\"\n",
    "    )\n",
    ")\n",
    "fig.write_html(\"plotly/perc_speakers.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e868cf9e",
   "metadata": {},
   "source": [
    "### Top speakers by gender/month plot\n",
    "\n",
    "Once again, we'll use `plotly` for the interactive plot for the highest quoted speaker by gender, in each month.\n",
    "\n",
    "For this, we'll create a new DataFrame with columns `gender`, `speaker`, `date` and `quotations` (which is the same as `numOccurrences`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80aaba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_speakers_df = pd.DataFrame([], columns = ['gender', 'speaker', 'date', 'quotations'])\n",
    "\n",
    "i = 0\n",
    "for gender in genders:\n",
    "    for j,month in enumerate(all_months):\n",
    "\n",
    "         # Get top speaker by gender/month\n",
    "         speaker, occurrences = speaker_df[gender][month].sort_values(by='numOccurrences', ascending = False).iloc[0]\n",
    "         top_speakers_df.loc[i] = [gender, speaker, month_str[j], int(occurrences)]\n",
    "         i+=1\n",
    "    i+=1\n",
    "\n",
    "# Convert numOccurrences column to int\n",
    "top_speakers_df.quotations = top_speakers_df.quotations.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "274ea918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>speaker</th>\n",
       "      <th>date</th>\n",
       "      <th>quotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>2015-1</td>\n",
       "      <td>37099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>2015-2</td>\n",
       "      <td>32215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>Jesus `` Chuy '' Garcia</td>\n",
       "      <td>2015-3</td>\n",
       "      <td>33467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>2015-4</td>\n",
       "      <td>27154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>2015-5</td>\n",
       "      <td>14155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>genderfluid</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>2019-12</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>genderfluid</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>2020-1</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>genderfluid</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>2020-2</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>genderfluid</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>2020-3</td>\n",
       "      <td>1147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>genderfluid</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>2020-4</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          gender                  speaker     date  quotations\n",
       "0           male             Barack Obama   2015-1       37099\n",
       "1           male             Barack Obama   2015-2       32215\n",
       "2           male  Jesus `` Chuy '' Garcia   2015-3       33467\n",
       "3           male             Barack Obama   2015-4       27154\n",
       "4           male             Barack Obama   2015-5       14155\n",
       "..           ...                      ...      ...         ...\n",
       "384  genderfluid              Miley Cyrus  2019-12         347\n",
       "385  genderfluid              Miley Cyrus   2020-1         180\n",
       "386  genderfluid              Miley Cyrus   2020-2         132\n",
       "387  genderfluid              Miley Cyrus   2020-3        1147\n",
       "388  genderfluid              Miley Cyrus   2020-4         230\n",
       "\n",
       "[384 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_speakers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f031a",
   "metadata": {},
   "source": [
    "We'll now create a bar plot with the highest quoted speakers of each gender, and add an animation slider to move between months. We save it to `plotly/top_speakers.html`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74cc57f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    top_speakers_df, \n",
    "    x='gender', \n",
    "    y = 'quotations', \n",
    "    animation_frame='date', \n",
    "    text = 'speaker',\n",
    "    hover_name='speaker',\n",
    "    hover_data={'gender':False, 'speaker':False, 'quotations':True, 'date':True},\n",
    "    color='gender',\n",
    "    title='Highest Quoted Speakers'\n",
    ")\n",
    "\n",
    "fig.update_yaxes(range=[0, 400000])\n",
    "\n",
    "fig.update_layout(\n",
    "    uniformtext_minsize=13,\n",
    "    uniformtext_mode='show', \n",
    "    showlegend=False,\n",
    "    hovermode='x',\n",
    "    yaxis=dict( # Disable yaxis\n",
    "        visible = True\n",
    "    ),\n",
    "    xaxis=dict( # Remove xaxis title\n",
    "        title=''\n",
    "    ),\n",
    "    hoverlabel=dict( # Change font on hover tool\n",
    "        font_size=16,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.write_html(\"plotly/top_speakers.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf7d74d-4c50-46d0-9283-c720aadefc90",
   "metadata": {},
   "source": [
    "# Topic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38040be8-43dd-4e36-908d-37c7b80e7a1e",
   "metadata": {},
   "source": [
    "Like on the section above, we'll start by retrieving the relevant information from the pre-processed data. The code to do that is presented below.\n",
    "\n",
    "To analyze the data, we'll run it through empath to determine what is the number of words spoken about each category. Before we do that, we'll add two new categories to empath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfc845b-0705-47c4-b3a3-816850bf1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = Empath()\n",
    "\n",
    "lexicon.create_category('climate_change', ['global_warming','green_house','death','water','fossil_fuel','burning','summit','environment','energy','renewable','consumption','petrol','gas','wind','solar_power','earth'], model='nytimes')\n",
    "lexicon.create_category('lgbt', ['rights', 'gay', 'trans', 'discriminantion', 'phobia', 'lesbian', 'transsexual','cis','queer','asexual','heterosexual','straight'], model='nytimes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1da2ca2-74f7-440a-8d01-80c028fdce22",
   "metadata": {},
   "source": [
    "Now we can process all the data by chuncks, and store the results to use later. The results will be written on one file per year, inside `./data_processed` and they will be called `empath_<year>.txt`.\n",
    "\n",
    "The internal structure of these files is the following.\n",
    "- First line: Distribution of the number of words per gender, per month. This information is displayed inside of a dictionary, where the keys are the genders found for that year, and to each key we have associated a list with 12 entries, one for each month, containing the number of words said by that gender in that month.\n",
    "- Second line: Number of chunks processed. No real functional purpose but it allowed to restart the program from a certain point if it got interrupted.\n",
    "- Third line: All the information extracted from the data. This information is displayed inside of a dictionary, where the keys correspond to the genders found for that year. Each key points to a list with 12 entries, one for each month. And in each entry of the list there is another dictionary, which is the output of empath for that month, where the keys correspond to the topics 'eating', 'alcohol', 'cleaning', 'sports',..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38233d2-c223-4dd3-ad09-8806063b4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_quotes = []\n",
    "# read all the pre-processed files and store them\n",
    "for file in glob.glob(data_folder + data_file):\n",
    "    dfs_quotes.append(pd.read_json(file, lines=True, chunksize=1e4))\n",
    "\n",
    "start = timeit.default_timer()\n",
    "# create a set with all the stopwords so we can remove them\n",
    "stop_words = set(stopwords.words())\n",
    "# iterate through all the files, each one corresponding to one year\n",
    "for year, file in enumerate(dfs_quotes):\n",
    "    themes = {}\n",
    "    n_words = {}\n",
    "    i = 0\n",
    "    # we need to read the file in chuncks, they are too big\n",
    "    for chunk in file:\n",
    "        tokens = {}\n",
    "        # extract the info about quotes, dates and genders\n",
    "        quotes = chunk['tokens'].tolist()\n",
    "        date = chunk['date'].tolist()\n",
    "        gender = chunk['gender'].tolist()\n",
    "        clean_quotes = []\n",
    "        for index, words in enumerate(quotes):\n",
    "            # remove stopwords and join the split tokens\n",
    "            processed_quote = [word for word in words if word not in stop_words]\n",
    "            clean_quotes.append(' '.join(processed_quote))\n",
    "            # if we have not yet added this gender to the number of words, we add it\n",
    "            if gender[index] not in n_words.keys():\n",
    "                n_words[gender[index]] = [0 for _ in range(12)]\n",
    "            # and then we sum the words in this quote\n",
    "            n_words[gender[index]][int(str(date[index])[5:7]) - 1] += len(processed_quote)\n",
    "\n",
    "        # now we divide all the quotes by their dates and genders, to make it easier to process them\n",
    "        for index, quote in enumerate(clean_quotes):\n",
    "            if gender[index] not in tokens.keys():\n",
    "                tokens[gender[index]] = [[] for _ in range(12)]\n",
    "            tokens[gender[index]][int(str(date[index])[5:7]) - 1].append(quote)\n",
    "        \n",
    "        # and finally we iterate through all the genders and all the months....\n",
    "        for gender in tokens.keys():\n",
    "            # we create the necessary entries in the dict\n",
    "            if gender not in themes.keys():\n",
    "                themes[gender] = [{} for _ in range(12)]\n",
    "                # and we analyze the quotes by topics\n",
    "                for month,quotes in enumerate(tokens[gender]):\n",
    "                    themes[gender][month]= lexicon.analyze(quotes, normalize = False)\n",
    "            # if the gender was already in the dictionary, we add the new info to the info that was already there\n",
    "            else:\n",
    "                for month,quotes in enumerate(tokens[gender]):\n",
    "                    themes_partial = lexicon.analyze(quotes, normalize = False)\n",
    "                    themes[gender][month] = {k: themes[gender][month].get(k, 0) + themes_partial.get(k, 0) for k in themes[gender][month].keys() | themes_partial.keys()}\n",
    "\n",
    "        i += 1\n",
    "        # we write the info to the file every 10 chunks so we don't have to start over if it crashes\n",
    "        if i % 10 == 0:\n",
    "            with open(f'./data_processed/empath_{year + 2015}.txt', 'w') as f:\n",
    "                f.write(f'Num words: {n_words}\\n')\n",
    "                f.write(f'Chunks processed: {i}\\n')\n",
    "                f.write(json.dumps(themes))\n",
    "            print(i, end = ',')\n",
    "\n",
    "    # at the end we write it all one last time\n",
    "    with open(f'./data_processed/empath_{year + 2015}.txt', 'w') as f:\n",
    "        f.write(f'Num words: {n_words} \\n')\n",
    "        f.write(f'Chunks processed: {i} \\n')\n",
    "        f.write(json.dumps(themes))\n",
    "    print()\n",
    "\n",
    "\n",
    "print(f'Time to analyze all chunks {timeit.default_timer() - start}!!')        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa808581-7069-4679-8805-f472fec552f2",
   "metadata": {},
   "source": [
    "After the analysis is done, we can simply get the relevant data from the saved files, which is much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bcb7f9-c2fc-4e22-a427-2b52ba8b1cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "empath_files = glob.glob('./data_processed/empath*.txt')\n",
    "\n",
    "n_words = []\n",
    "empath_data = []\n",
    "\n",
    "for file in empath_files:\n",
    "    with open(file, 'r') as f:\n",
    "        txt = f.read()\n",
    "        txt = txt.split('\\n')\n",
    "        \n",
    "        n_words.append(eval(txt[0][11:]))\n",
    "        empath_data.append(eval(txt[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1bd61a-2aa2-4aaf-855d-90968ba09554",
   "metadata": {},
   "source": [
    "We also save this data as a normalized version, because it will be useful for plotting purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c521d5b4-c1c6-4b7a-8e02-4d29eb4bdb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "empath_data_norm = copy.deepcopy(empath_data)\n",
    "\n",
    "for year, data in enumerate(empath_data_norm):\n",
    "    for gender in data:\n",
    "        for month, datum in enumerate(data[gender]):\n",
    "            for key in datum:\n",
    "                if n_words[year][gender][month] != 0:\n",
    "                    datum[key] = datum.get(key, 1) / n_words[year][gender][month] * 100   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6090d9ba-2f45-41fe-8d1b-fd15faa09166",
   "metadata": {},
   "source": [
    "Now we convert these dictionaries into a list of tuples, so that we can sort them, while keeping only the main list of genders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77a8601-5072-44a8-9901-e3a58aeb2b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data = []\n",
    "genders = ['male', 'female', 'transgender male', 'transgender female', 'non-binary', 'genderfluid']\n",
    "\n",
    "for data in empath_data:\n",
    "    temp_data = {}\n",
    "    for gender in data:\n",
    "        if gender in genders:\n",
    "            temp_data[gender] = [[] for _ in range(12)]\n",
    "            for month, datum in enumerate(data[gender]):\n",
    "                temp_data[gender][month] = list(datum.items())\n",
    "                temp_data[gender][month].sort(key=lambda tup:tup[1], reverse=True)\n",
    "    sorted_data.append(temp_data)\n",
    "\n",
    "sorted_data_norm = []\n",
    "for data in empath_data_norm:\n",
    "    temp_data = {}\n",
    "    for gender in data:\n",
    "        if gender in genders:\n",
    "            temp_data[gender] = [[] for _ in range(12)]\n",
    "            for month, datum in enumerate(data[gender]):\n",
    "                temp_data[gender][month] = list(datum.items())\n",
    "                temp_data[gender][month].sort(key=lambda top:top[1], reverse=True)\n",
    "    sorted_data_norm.append(temp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf9956c-0ba5-458f-a235-34a52f8604fd",
   "metadata": {},
   "source": [
    "With them sorted, we can prepare the information to start plotting it. For that, let's only consider a subset of key topics:\n",
    "- Business\n",
    "- Sports\n",
    "- Government\n",
    "- Climate Change\n",
    "- LGBT\n",
    "- Money\n",
    "- Family\n",
    "- Health\n",
    "\n",
    "For only these topics, we'll save their information, both in raw and normalized format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d3c5fb-c30a-4ac6-8827-2753abbc4544",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = {'business': {},\n",
    "          'sports': {},\n",
    "          'government': {},\n",
    "          'climate_change': {},\n",
    "          'lgbt': {},\n",
    "          'money': {},\n",
    "          'family': {},\n",
    "          'health': {}\n",
    "         }\n",
    "\n",
    "for year, data in enumerate(sorted_data):\n",
    "    for gender in data:\n",
    "        for datum in data[gender]:\n",
    "            for topic in datum:\n",
    "                if topic[0] in topics.keys():\n",
    "                    if gender in topics[topic[0]].keys():\n",
    "                        topics[topic[0]][gender].append(topic[1])\n",
    "                    else:\n",
    "                        topics[topic[0]][gender] = [topic[1]]\n",
    "                        \n",
    "topics_norm = {'business': {},\n",
    "               'sports': {},\n",
    "               'government': {},\n",
    "               'climate_change': {},\n",
    "               'lgbt': {},\n",
    "               'money': {},\n",
    "               'family': {},\n",
    "               'health': {}\n",
    "              }\n",
    "\n",
    "for year, data in enumerate(sorted_data_norm):\n",
    "    for gender in data:\n",
    "        for datum in data[gender]:\n",
    "            for topic in datum:\n",
    "                if topic[0] in topics_norm.keys():\n",
    "                    if gender in topics_norm[topic[0]].keys():\n",
    "                        topics_norm[topic[0]][gender].append(topic[1])\n",
    "                    else:\n",
    "                        topics_norm[topic[0]][gender] = [topic[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205d19f9-e672-4cf4-b8cd-4bf341c710dc",
   "metadata": {},
   "source": [
    "Now we can finally get started on the plots. The first one we'll create is a dynamic graph showing the evolution of the distribution of topics per gender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ba7931-d386-4943-b6bd-08716a0dfa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell will plot the distribution of topics per gender\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# we prepare our data for plotting\n",
    "genders_show = [' '.join([word.capitalize() for word in gender.split()]) for gender in genders]\n",
    "\n",
    "plot_values_norm = {'gender': [],\n",
    "                    'topic': [],\n",
    "                    'percentage': [],\n",
    "                    'date':[]\n",
    "                   }\n",
    "\n",
    "for gender in genders:\n",
    "    for topic in topics_norm:\n",
    "        for index, val in enumerate(topics_norm[topic][gender]):\n",
    "            if all(np.array(topics_norm[topic][gender][index:]) == 0):\n",
    "                break\n",
    "            month = index % 12 + 1\n",
    "            year = 2015 + index // 12\n",
    "            plot_values_norm['gender'].append(gender)\n",
    "            plot_values_norm['topic'].append(topic)\n",
    "            plot_values_norm['percentage'].append(val)\n",
    "            plot_values_norm['date'].append(f'{year}-{month:02}')\n",
    "            \n",
    "plot_values_norm = pd.DataFrame.from_dict(plot_values_norm)\n",
    "\n",
    "fig = px.bar(plot_values_norm,\n",
    "             x='gender',\n",
    "             y='percentage',\n",
    "             color='topic',\n",
    "             title='Distribution of Key Topics per Gender',\n",
    "             animation_frame='date',\n",
    "             height=750,\n",
    "             range_y=[min(plot_values_norm['percentage']), max(plot_values_norm['percentage'])],\n",
    "             barmode='group',\n",
    "             hover_name='topic',\n",
    "             hover_data={'gender':False, 'topic':False, 'percentage':True, 'date':False},\n",
    "             )\n",
    "\n",
    "fig.update_layout(\n",
    "    # xaxis_title=\"Gender\",\n",
    "    yaxis_title=\"Percentage of Words about Topic in Quotes by Gender\",\n",
    ")\n",
    "\n",
    "fig.write_html(\"./topic_in_gender.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea5d535-b0ab-4378-a8d1-89a618ab3826",
   "metadata": {},
   "source": [
    "The second plot is also a dynamic graph, but this time showing the distribution of genders inside a given topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6eceea-0cef-4709-bb09-fcf03bb12b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is for showing the gender distribution for any topic\n",
    "# this cell will be for the overall topic evolution\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# we prepare our data for plotting\n",
    "genders_show = [' '.join([word.capitalize() for word in gender.split()]) for gender in genders]\n",
    "\n",
    "plot_values_abs = {'gender': [],\n",
    "                   'topic': [],\n",
    "                   'counts': [],\n",
    "                   'date':[]\n",
    "                  }\n",
    "\n",
    "for gender in genders:\n",
    "    for topic in topics:\n",
    "        for index, val in enumerate(topics[topic][gender]):\n",
    "            if all(np.array(topics[topic][gender][index:]) == 0):\n",
    "                break\n",
    "            month = index % 12 + 1\n",
    "            year = 2015 + index // 12\n",
    "            plot_values_abs['gender'].append(gender)\n",
    "            plot_values_abs['topic'].append(topic)\n",
    "            plot_values_abs['counts'].append(val)\n",
    "            plot_values_abs['date'].append(f'{year}-{month:02}')\n",
    "            \n",
    "plot_values_abs = pd.DataFrame.from_dict(plot_values_abs)\n",
    "\n",
    "fig = px.bar(plot_values_abs,\n",
    "             x='topic',\n",
    "             y='counts',\n",
    "             color='gender',\n",
    "             title='Distribution of Genders per Key Topic',\n",
    "             animation_frame='date',\n",
    "             height=750,\n",
    "             range_y=[max(min(plot_values_abs['counts']),1), max(plot_values_abs['counts'])],\n",
    "             log_y = True,\n",
    "             barmode='group',\n",
    "             hover_name='gender',\n",
    "             hover_data={'gender':False, 'topic':False, 'counts':True, 'date':False},\n",
    "             )\n",
    "\n",
    "fig.update_layout(\n",
    "    #xaxis_title=\"Topic\",\n",
    "    yaxis_title=\"Word Counts by Gender per Topic\",\n",
    ")\n",
    "\n",
    "fig.write_html(\"./gender_in_topic.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b51fec-4913-44e7-a6b9-47e0a62ab7d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173f1d52-5248-47df-bc13-76c95ae79b38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
