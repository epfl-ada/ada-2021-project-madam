{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579d5f83-5f2b-4c66-88d9-b431f81fc88e",
   "metadata": {},
   "source": [
    "**This is the final notebook for Milestone 3, where all the data analysis (besides the pre processing done in Milestone 2) is done.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9869f0-3c97-41a8-9607-7e687124bec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math \n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import timeit\n",
    "import bz2\n",
    "import datetime\n",
    "import sys\n",
    "from empath import Empath\n",
    "import json\n",
    "import glob\n",
    "#from src.prep_utilities import * \n",
    "#from src.prep_pipeline import *\n",
    "\n",
    "# Load nltk models\n",
    "#!python ./src/load_models_data.py\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "!python ./src/load_models_data.py\n",
    "data_folder = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d4b783-5da9-4b16-9509-02f235c96892",
   "metadata": {},
   "source": [
    "# General Gender Bias Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9303118b-78e0-4843-a49d-a32d742ee8c5",
   "metadata": {},
   "source": [
    "In this section, we plan to analyse:\n",
    " - Evolution of percentage of speakers by gender, over time\n",
    " - Evolution of percentage of quotations by gender, over time\n",
    " - Most quoted speakers by gender, over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dfe526-ce0b-46a1-a259-81af57e00d63",
   "metadata": {},
   "source": [
    "We'll do a month-by-month analysis. For each month/gender combination, we'll save a Dataframe with the speakers and their total number of quotations that month.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb66d116-43d5-48a7-9b61-18e0caa774b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time ranges\n",
    "years = range(2015,2021)\n",
    "min_month = \"2015-01\"\n",
    "max_month = \"2020-04\"\n",
    "all_months = pd.period_range(min_month, max_month, freq='M')\n",
    "\n",
    "genders = ['male', 'female', 'transgender male', 'transgender female', 'non-binary', 'genderfluid']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "595d55ad-2d98-4273-846c-7ed0f62656ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionaries we'll use to store analysis\n",
    "\n",
    "speaker_df = {} # Save the dataframes of top speakers by gender/month\n",
    "\n",
    "for gender in genders:  \n",
    "    speakers_df_temp = {}\n",
    "    \n",
    "    for month in all_months:\n",
    "\n",
    "        speakers_df_temp[month] = pd.DataFrame([], columns = ['speaker', 'numOccurrences']).set_index('speaker')\n",
    "\n",
    "    speaker_df[gender] = speakers_df_temp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9410e3e-bef4-49b8-a2d9-efe7de556318",
   "metadata": {},
   "source": [
    "The pre-processed data will be loaded each year, by chunks. In the analyses, we will cycle through each year, and through each chunk, and save the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "318cc39e-f9f2-4227-a606-b6d1821e93b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing year 2015... Done in 1399.95s\n",
      "Analysing year 2016... Done in 829.45s\n",
      "Analysing year 2017... Done in 2002.01s\n",
      "Analysing year 2018... Done in 2067.94s\n",
      "Analysing year 2019... Done in 1489.73s\n",
      "Analysing year 2020... Done in 164.27s\n"
     ]
    }
   ],
   "source": [
    "# Loop through years\n",
    "for year in years:\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    # data location and chunk size\n",
    "    data_file = 'quotes-'+ str(year)+'-prep.json.bz2'\n",
    "    data_path = data_folder + data_file\n",
    "    chunk_size = 1e4\n",
    "\n",
    "    # Load by chunks\n",
    "    f = bz2.open(data_path, \"rb\")\n",
    "    data=pd.read_json(f, lines=True, chunksize=chunk_size)\n",
    "    \n",
    "    print(f\"Analysing year {year}...\", end=\" \")\n",
    "    \n",
    "\n",
    "    # Loop through chunks\n",
    "    for i_chunk, chunk in enumerate(data):\n",
    "        \n",
    "        ## Run analysis ##\n",
    "        \n",
    "        # Create range of months for this year\n",
    "        if year != 2020:\n",
    "            months = pd.period_range(str(year)+'-'+'01', str(year)+'-'+'12', freq='M')\n",
    "        else:\n",
    "            months = pd.period_range(str(year)+'-'+'01', str(year)+'-'+'04', freq='M')\n",
    "\n",
    "        # Loop through months\n",
    "        for month in months:\n",
    "            # Mask to select desired month\n",
    "            month_mask = (chunk['date'].dt.to_period('m') == month)\n",
    "            \n",
    "            # Loop through genders\n",
    "            for gender in genders:\n",
    "                \n",
    "                # Mask to select desired gender\n",
    "                gender_mask = (chunk['gender'] == gender)\n",
    "                \n",
    "                # Concatenate the speakers in this chunk with our dictionary\n",
    "                df = chunk[gender_mask & month_mask].groupby(\"speaker\").sum()\n",
    "                speaker_df[gender][month] = pd.concat([speaker_df[gender][month],df]).groupby(\"speaker\").sum()\n",
    "\n",
    "    stop = timeit.default_timer()\n",
    "    print(f\"Done in {stop-start:.2f}s\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227a8e76-f638-4cd4-8cf6-004d20d50a2d",
   "metadata": {},
   "source": [
    "Since we don't want to run the previous cell everytime we reload the notebook, we'll save each of the gender/month combinations to a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96efe899-da28-4dee-8879-76aa0d5406ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_analysis_folder = './data_processed/'\n",
    "\n",
    "for gender in genders:\n",
    "    for month in all_months:\n",
    "        with bz2.open(general_analysis_folder + gender +'-' + str(month.year) + '-' + str(month.month) + '.json.bz2', \"w\") as f:\n",
    "\n",
    "            # Write to file, reset index to keep the speaker's names\n",
    "            write = speaker_df[gender][month].reset_index().to_json(f, lines=True, orient='records') \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5167305f-0efc-434f-a566-7016fe3a9b39",
   "metadata": {},
   "source": [
    "Now that we've created the files with the analysis data, let's read them again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c421df4-17b9-46d6-b13d-aa58cc34f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_df = {} # Load the dataframes of top speakers by gender/month\n",
    "general_analysis_folder = './data_processed/'\n",
    "\n",
    "for gender in genders:  \n",
    "    speakers_df_temp = {}\n",
    "    for month in all_months:\n",
    "        speakers_df_temp[month] = pd.read_json(general_analysis_folder + gender +'-' + str(month.year) + '-' + str(month.month) + '.json.bz2', lines = True,compression = 'bz2')\n",
    "        \n",
    "        # Join rows of presidential aliases (President Trump, Donald Trump, etc...)\n",
    "        speakers_df_temp[month] = speakers_df_temp[month].replace([\"President Barack Obama\", \"President Obama\"], \"Barack Obama\")\n",
    "        speakers_df_temp[month] = speakers_df_temp[month].replace([\"President Donald Trump\", \"President Trump\"], \"Donald Trump\")\n",
    "        speakers_df_temp[month] = speakers_df_temp[month].groupby('speaker').sum().reset_index()\n",
    "\n",
    "    speaker_df[gender] = speakers_df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f3df3b-023d-423b-8776-92465630fb02",
   "metadata": {},
   "source": [
    "## Plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07593b46",
   "metadata": {},
   "source": [
    "### Percentage of quotations and speakers by gender\n",
    "\n",
    "We will use the package `plotly` to make an interactive plot with our data in the cells below.\n",
    "\n",
    "To view the plot, double click `plotly/general_quotations_speakers.html`.\n",
    "\n",
    "First, we create DataFrames to hold the plot data, and then we plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d78614a-4a87-4ad1-9ea8-496f23c81615",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare data to be plotted ##\n",
    "\n",
    "# x data\n",
    "month_str = [str(month.year)+'-'+str(month.month) for month in all_months]\n",
    "month_dt = [datetime.datetime.strptime(x, '%Y-%m') for x in month_str]\n",
    "\n",
    "# y data\n",
    "total_quotations = {} # total quotations by month\n",
    "total_speakers = {} # total number of speakers by month\n",
    "\n",
    "# Dictionaries with total values for each month\n",
    "for month in all_months:\n",
    "    total_quotations[month] = 0\n",
    "    total_speakers[month] = 0\n",
    "\n",
    "    for gender in genders:\n",
    "        total_quotations[month] += speaker_df[gender][month]['numOccurrences'].sum()\n",
    "        total_speakers[month] += len(speaker_df[gender][month])\n",
    "\n",
    "perc_quotations = pd.DataFrame([], columns = genders) # df with the dates and percentage of quotations by gender\n",
    "perc_speakers =  pd.DataFrame([], columns = genders) # df with the dates and percentage of speakers by gender\n",
    "\n",
    "for i,month in enumerate(all_months):\n",
    "    perc_quotations.loc[i] = [100*speaker_df[gender][month]['numOccurrences'].sum()/total_quotations[month] for gender in genders]\n",
    "    perc_speakers.loc[i] = [100*len(speaker_df[gender][month])/total_speakers[month] for gender in genders]\n",
    "    \n",
    "perc_quotations['date'] = month_dt # Dates for x axis\n",
    "perc_speakers['date'] = month_dt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3c4b11",
   "metadata": {},
   "source": [
    "Run the cell below to generate the \"Percentage of Occurrences by Gender\" plot. Double click `plotly/perc_quotations.html` to view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "412584b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Color palette\n",
    "palette = px.colors.qualitative.Plotly\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "fig.update_layout(title = 'Percentage of Occurrences by Gender')\n",
    "fig.update_xaxes(title='Date')\n",
    "fig.update_yaxes(title='Percentage of Occurrences')\n",
    "\n",
    "# Add plots (they have to be added by order, in order not to mess up the 'visible' lists)\n",
    "for i,gender in enumerate(genders):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x = perc_quotations['date'], y = perc_quotations[gender], name = gender, mode='lines', line=dict(color=palette[i], width=3))\n",
    "        )\n",
    "\n",
    "\n",
    "visible_quotations = [True if i<6 else False for i in range(12)]\n",
    "visible_speakers = [not x for x in visible_quotations]\n",
    "\n",
    "# Add x range slider\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        rangeslider=dict(\n",
    "            visible=True\n",
    "        ),\n",
    "        type=\"date\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.write_html(\"./plotly/perc_quotations.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4a084b",
   "metadata": {},
   "source": [
    "Run the cell below to generate the \"Percentage of Speakers by Gender\" plot. Double click `plotly/perc_speakers.html` to view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d97c12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Color palette\n",
    "palette = px.colors.qualitative.Plotly\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "fig.update_layout(title = 'Percentage of Speakers by Gender')\n",
    "fig.update_xaxes(title='Date')\n",
    "fig.update_yaxes(title='Percentage of Speakers')\n",
    "\n",
    "# Add plots\n",
    "for i,gender in enumerate(genders):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x = perc_speakers['date'], y = perc_speakers[gender], name = gender, mode='lines', line=dict(color=palette[i], width=3))\n",
    "        )\n",
    "\n",
    "# Add x range slider\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        rangeslider=dict(\n",
    "            visible=True\n",
    "        ),\n",
    "        type=\"date\"\n",
    "    )\n",
    ")\n",
    "fig.write_html(\"./plotly/perc_speakers.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e868cf9e",
   "metadata": {},
   "source": [
    "### Top speakers by gender/month plot\n",
    "\n",
    "Once again, we'll use `plotly` for the interactive plot for the highest quoted speaker by gender, in each month.\n",
    "\n",
    "For this, we'll create a new DataFrame with columns `gender`, `speaker`, `date` and `occurrences` (which is the same as `numOccurrences`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80aaba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_speakers_df = pd.DataFrame([], columns = ['gender', 'speaker', 'date', 'occurrences'])\n",
    "\n",
    "i = 0\n",
    "for gender in genders:\n",
    "    for j,month in enumerate(all_months):\n",
    "        # Get top speaker by gender/month\n",
    "        speaker, occurrences = speaker_df[gender][month].sort_values(by='numOccurrences', ascending = False).iloc[0]\n",
    "        top_speakers_df.loc[i] = [gender, speaker, month_str[j], int(occurrences)]\n",
    "        i+=1\n",
    "    i+=1\n",
    "\n",
    "# Convert numOccurrences column to int\n",
    "top_speakers_df.occurrences = top_speakers_df.occurrences.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "274ea918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>speaker</th>\n",
       "      <th>date</th>\n",
       "      <th>occurrences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>2015-1</td>\n",
       "      <td>37099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>2015-2</td>\n",
       "      <td>32215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>Jesus `` Chuy '' Garcia</td>\n",
       "      <td>2015-3</td>\n",
       "      <td>33467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>2015-4</td>\n",
       "      <td>27154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>2015-5</td>\n",
       "      <td>14155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>genderfluid</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>2019-12</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>genderfluid</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>2020-1</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>genderfluid</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>2020-2</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>genderfluid</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>2020-3</td>\n",
       "      <td>1147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>genderfluid</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>2020-4</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          gender                  speaker     date  occurrences\n",
       "0           male             Barack Obama   2015-1        37099\n",
       "1           male             Barack Obama   2015-2        32215\n",
       "2           male  Jesus `` Chuy '' Garcia   2015-3        33467\n",
       "3           male             Barack Obama   2015-4        27154\n",
       "4           male             Barack Obama   2015-5        14155\n",
       "..           ...                      ...      ...          ...\n",
       "384  genderfluid              Miley Cyrus  2019-12          347\n",
       "385  genderfluid              Miley Cyrus   2020-1          180\n",
       "386  genderfluid              Miley Cyrus   2020-2          132\n",
       "387  genderfluid              Miley Cyrus   2020-3         1147\n",
       "388  genderfluid              Miley Cyrus   2020-4          230\n",
       "\n",
       "[384 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_speakers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f031a",
   "metadata": {},
   "source": [
    "We'll now create a bar plot with the highest quoted speakers of each gender, and add an animation slider to move between months. We save it to `plotly/top_speakers.html`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74cc57f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    top_speakers_df, \n",
    "    x='gender', \n",
    "    y = 'quotations', \n",
    "    animation_frame='date', \n",
    "    text = 'speaker',\n",
    "    hover_name='speaker',\n",
    "    hover_data={'gender':False, 'speaker':False, 'quotations':True, 'date':True},\n",
    "    color='gender',\n",
    "    title='Highest Quoted Speakers'\n",
    ")\n",
    "\n",
    "fig.update_yaxes(range=[0, 400000])\n",
    "\n",
    "fig.update_layout(\n",
    "    uniformtext_minsize=13,\n",
    "    uniformtext_mode='show', \n",
    "    showlegend=False,\n",
    "    hovermode='x',\n",
    "    yaxis=dict( # Disable yaxis\n",
    "        visible = True\n",
    "    ),\n",
    "    xaxis=dict( # Remove xaxis title\n",
    "        title=''\n",
    "    ),\n",
    "    hoverlabel=dict( # Change font on hover tool\n",
    "        font_size=16,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.write_html(\"./plotly/top_speakers.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf7d74d-4c50-46d0-9283-c720aadefc90",
   "metadata": {},
   "source": [
    "# Topic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38040be8-43dd-4e36-908d-37c7b80e7a1e",
   "metadata": {},
   "source": [
    "Like on the section above, we'll start by retrieving the relevant information from the pre-processed data. The code to do that is presented below.\n",
    "\n",
    "To analyze the data, we'll run it through empath to determine what is the number of words spoken about each category. Before we do that, we'll add two new categories to empath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfc845b-0705-47c4-b3a3-816850bf1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = Empath()\n",
    "\n",
    "lexicon.create_category('climate_change', ['global_warming','green_house','death','water','fossil_fuel','burning','summit','environment','energy','renewable','consumption','petrol','gas','wind','solar_power','earth'], model='nytimes')\n",
    "lexicon.create_category('lgbt', ['rights', 'gay', 'trans', 'discriminantion', 'phobia', 'lesbian', 'transsexual','cis','queer','asexual','heterosexual','straight'], model='nytimes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1da2ca2-74f7-440a-8d01-80c028fdce22",
   "metadata": {},
   "source": [
    "Now we can process all the data by chuncks, and store the results to use later. The results will be written on one file per year, inside `./data_processed` and they will be called `empath_<year>.txt`.\n",
    "\n",
    "The internal structure of these files is the following.\n",
    "- First line: Distribution of the number of words per gender, per month. This information is displayed inside of a dictionary, where the keys are the genders found for that year, and to each key we have associated a list with 12 entries, one for each month, containing the number of words said by that gender in that month.\n",
    "- Second line: Number of chunks processed. No real functional purpose but it allowed to restart the program from a certain point if it got interrupted.\n",
    "- Third line: All the information extracted from the data. This information is displayed inside of a dictionary, where the keys correspond to the genders found for that year. Each key points to a list with 12 entries, one for each month. And in each entry of the list there is another dictionary, which is the output of empath for that month, where the keys correspond to the topics 'eating', 'alcohol', 'cleaning', 'sports',..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38233d2-c223-4dd3-ad09-8806063b4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_quotes = []\n",
    "# read all the pre-processed files and store them\n",
    "for file in glob.glob(data_folder + data_file):\n",
    "    dfs_quotes.append(pd.read_json(file, lines=True, chunksize=1e4))\n",
    "\n",
    "start = timeit.default_timer()\n",
    "# create a set with all the stopwords so we can remove them\n",
    "stop_words = set(stopwords.words())\n",
    "# iterate through all the files, each one corresponding to one year\n",
    "for year, file in enumerate(dfs_quotes):\n",
    "    themes = {}\n",
    "    n_words = {}\n",
    "    i = 0\n",
    "    # we need to read the file in chuncks, they are too big\n",
    "    for chunk in file:\n",
    "        tokens = {}\n",
    "        # extract the info about quotes, dates and genders\n",
    "        quotes = chunk['tokens'].tolist()\n",
    "        date = chunk['date'].tolist()\n",
    "        gender = chunk['gender'].tolist()\n",
    "        clean_quotes = []\n",
    "        for index, words in enumerate(quotes):\n",
    "            # remove stopwords and join the split tokens\n",
    "            processed_quote = [word for word in words if word not in stop_words]\n",
    "            clean_quotes.append(' '.join(processed_quote))\n",
    "            # if we have not yet added this gender to the number of words, we add it\n",
    "            if gender[index] not in n_words.keys():\n",
    "                n_words[gender[index]] = [0 for _ in range(12)]\n",
    "            # and then we sum the words in this quote\n",
    "            n_words[gender[index]][int(str(date[index])[5:7]) - 1] += len(processed_quote)\n",
    "\n",
    "        # now we divide all the quotes by their dates and genders, to make it easier to process them\n",
    "        for index, quote in enumerate(clean_quotes):\n",
    "            if gender[index] not in tokens.keys():\n",
    "                tokens[gender[index]] = [[] for _ in range(12)]\n",
    "            tokens[gender[index]][int(str(date[index])[5:7]) - 1].append(quote)\n",
    "        \n",
    "        # and finally we iterate through all the genders and all the months....\n",
    "        for gender in tokens.keys():\n",
    "            # we create the necessary entries in the dict\n",
    "            if gender not in themes.keys():\n",
    "                themes[gender] = [{} for _ in range(12)]\n",
    "                # and we analyze the quotes by topics\n",
    "                for month,quotes in enumerate(tokens[gender]):\n",
    "                    themes[gender][month]= lexicon.analyze(quotes, normalize = False)\n",
    "            # if the gender was already in the dictionary, we add the new info to the info that was already there\n",
    "            else:\n",
    "                for month,quotes in enumerate(tokens[gender]):\n",
    "                    themes_partial = lexicon.analyze(quotes, normalize = False)\n",
    "                    themes[gender][month] = {k: themes[gender][month].get(k, 0) + themes_partial.get(k, 0) for k in themes[gender][month].keys() | themes_partial.keys()}\n",
    "\n",
    "        i += 1\n",
    "        # we write the info to the file every 10 chunks so we don't have to start over if it crashes\n",
    "        if i % 10 == 0:\n",
    "            with open(f'./data_processed/empath_{year + 2015}.txt', 'w') as f:\n",
    "                f.write(f'Num words: {n_words}\\n')\n",
    "                f.write(f'Chunks processed: {i}\\n')\n",
    "                f.write(json.dumps(themes))\n",
    "            print(i, end = ',')\n",
    "\n",
    "    # at the end we write it all one last time\n",
    "    with open(f'./data_processed/empath_{year + 2015}.txt', 'w') as f:\n",
    "        f.write(f'Num words: {n_words} \\n')\n",
    "        f.write(f'Chunks processed: {i} \\n')\n",
    "        f.write(json.dumps(themes))\n",
    "    print()\n",
    "\n",
    "\n",
    "print(f'Time to analyze all chunks {timeit.default_timer() - start}!!')        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa808581-7069-4679-8805-f472fec552f2",
   "metadata": {},
   "source": [
    "After the analysis is done, we can simply get the relevant data from the saved files, which is much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bcb7f9-c2fc-4e22-a427-2b52ba8b1cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "empath_files = glob.glob('./data_processed/empath*.txt')\n",
    "\n",
    "n_words = []\n",
    "empath_data = []\n",
    "\n",
    "for file in empath_files:\n",
    "    with open(file, 'r') as f:\n",
    "        txt = f.read()\n",
    "        txt = txt.split('\\n')\n",
    "        \n",
    "        n_words.append(eval(txt[0][11:]))\n",
    "        empath_data.append(eval(txt[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1bd61a-2aa2-4aaf-855d-90968ba09554",
   "metadata": {},
   "source": [
    "We also save this data as a normalized version, because it will be useful for plotting purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c521d5b4-c1c6-4b7a-8e02-4d29eb4bdb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "empath_data_norm = copy.deepcopy(empath_data)\n",
    "\n",
    "for year, data in enumerate(empath_data_norm):\n",
    "    for gender in data:\n",
    "        for month, datum in enumerate(data[gender]):\n",
    "            for key in datum:\n",
    "                if n_words[year][gender][month] != 0:\n",
    "                    datum[key] = datum.get(key, 1) / n_words[year][gender][month] * 100   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6090d9ba-2f45-41fe-8d1b-fd15faa09166",
   "metadata": {},
   "source": [
    "Now we convert these dictionaries into a list of tuples, so that we can sort them, while keeping only the main list of genders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77a8601-5072-44a8-9901-e3a58aeb2b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data = []\n",
    "genders = ['male', 'female', 'transgender male', 'transgender female', 'non-binary', 'genderfluid']\n",
    "\n",
    "for data in empath_data:\n",
    "    temp_data = {}\n",
    "    for gender in data:\n",
    "        if gender in genders:\n",
    "            temp_data[gender] = [[] for _ in range(12)]\n",
    "            for month, datum in enumerate(data[gender]):\n",
    "                temp_data[gender][month] = list(datum.items())\n",
    "                temp_data[gender][month].sort(key=lambda tup:tup[1], reverse=True)\n",
    "    sorted_data.append(temp_data)\n",
    "\n",
    "sorted_data_norm = []\n",
    "for data in empath_data_norm:\n",
    "    temp_data = {}\n",
    "    for gender in data:\n",
    "        if gender in genders:\n",
    "            temp_data[gender] = [[] for _ in range(12)]\n",
    "            for month, datum in enumerate(data[gender]):\n",
    "                temp_data[gender][month] = list(datum.items())\n",
    "                temp_data[gender][month].sort(key=lambda top:top[1], reverse=True)\n",
    "    sorted_data_norm.append(temp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf9956c-0ba5-458f-a235-34a52f8604fd",
   "metadata": {},
   "source": [
    "With them sorted, we can prepare the information to start plotting it. For that, let's only consider a subset of key topics:\n",
    "- Business\n",
    "- Sports\n",
    "- Government\n",
    "- Climate Change\n",
    "- LGBT\n",
    "- Money\n",
    "- Family\n",
    "- Health\n",
    "\n",
    "For only these topics, we'll save their information, both in raw and normalized format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d3c5fb-c30a-4ac6-8827-2753abbc4544",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = {'business': {},\n",
    "          'sports': {},\n",
    "          'government': {},\n",
    "          'climate_change': {},\n",
    "          'lgbt': {},\n",
    "          'money': {},\n",
    "          'family': {},\n",
    "          'health': {}\n",
    "         }\n",
    "\n",
    "for year, data in enumerate(sorted_data):\n",
    "    for gender in data:\n",
    "        for datum in data[gender]:\n",
    "            for topic in datum:\n",
    "                if topic[0] in topics.keys():\n",
    "                    if gender in topics[topic[0]].keys():\n",
    "                        topics[topic[0]][gender].append(topic[1])\n",
    "                    else:\n",
    "                        topics[topic[0]][gender] = [topic[1]]\n",
    "                        \n",
    "topics_norm = {'business': {},\n",
    "               'sports': {},\n",
    "               'government': {},\n",
    "               'climate_change': {},\n",
    "               'lgbt': {},\n",
    "               'money': {},\n",
    "               'family': {},\n",
    "               'health': {}\n",
    "              }\n",
    "\n",
    "for year, data in enumerate(sorted_data_norm):\n",
    "    for gender in data:\n",
    "        for datum in data[gender]:\n",
    "            for topic in datum:\n",
    "                if topic[0] in topics_norm.keys():\n",
    "                    if gender in topics_norm[topic[0]].keys():\n",
    "                        topics_norm[topic[0]][gender].append(topic[1])\n",
    "                    else:\n",
    "                        topics_norm[topic[0]][gender] = [topic[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205d19f9-e672-4cf4-b8cd-4bf341c710dc",
   "metadata": {},
   "source": [
    "Now we can finally get started on the plots. The first one we'll create is a dynamic graph showing the evolution of the distribution of topics per gender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ba7931-d386-4943-b6bd-08716a0dfa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell will plot the distribution of topics per gender\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# we prepare our data for plotting\n",
    "genders_show = [' '.join([word.capitalize() for word in gender.split()]) for gender in genders]\n",
    "\n",
    "plot_values_norm = {'gender': [],\n",
    "                    'topic': [],\n",
    "                    'percentage': [],\n",
    "                    'date':[]\n",
    "                   }\n",
    "\n",
    "for gender in genders:\n",
    "    for topic in topics_norm:\n",
    "        for index, val in enumerate(topics_norm[topic][gender]):\n",
    "            if all(np.array(topics_norm[topic][gender][index:]) == 0):\n",
    "                break\n",
    "            month = index % 12 + 1\n",
    "            year = 2015 + index // 12\n",
    "            plot_values_norm['gender'].append(gender)\n",
    "            plot_values_norm['topic'].append(topic)\n",
    "            plot_values_norm['percentage'].append(val)\n",
    "            plot_values_norm['date'].append(f'{year}-{month:02}')\n",
    "            \n",
    "plot_values_norm = pd.DataFrame.from_dict(plot_values_norm)\n",
    "\n",
    "fig = px.bar(plot_values_norm,\n",
    "             x='gender',\n",
    "             y='percentage',\n",
    "             color='topic',\n",
    "             title='Distribution of Key Topics per Gender',\n",
    "             animation_frame='date',\n",
    "             height=750,\n",
    "             range_y=[min(plot_values_norm['percentage']), max(plot_values_norm['percentage'])],\n",
    "             barmode='group',\n",
    "             hover_name='topic',\n",
    "             hover_data={'gender':False, 'topic':False, 'percentage':True, 'date':False},\n",
    "             )\n",
    "\n",
    "fig.update_layout(\n",
    "    # xaxis_title=\"Gender\",\n",
    "    yaxis_title=\"Percentage of Words about Topic in Quotes by Gender\",\n",
    ")\n",
    "\n",
    "fig.write_html(\"./plotly/topic_in_gender.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea5d535-b0ab-4378-a8d1-89a618ab3826",
   "metadata": {},
   "source": [
    "The second plot is also a dynamic graph, but this time showing the distribution of genders inside a given topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6eceea-0cef-4709-bb09-fcf03bb12b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is for showing the gender distribution for any topic\n",
    "# this cell will be for the overall topic evolution\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# we prepare our data for plotting\n",
    "genders_show = [' '.join([word.capitalize() for word in gender.split()]) for gender in genders]\n",
    "\n",
    "plot_values_abs = {'gender': [],\n",
    "                   'topic': [],\n",
    "                   'counts': [],\n",
    "                   'date':[]\n",
    "                  }\n",
    "\n",
    "for gender in genders:\n",
    "    for topic in topics:\n",
    "        for index, val in enumerate(topics[topic][gender]):\n",
    "            if all(np.array(topics[topic][gender][index:]) == 0):\n",
    "                break\n",
    "            month = index % 12 + 1\n",
    "            year = 2015 + index // 12\n",
    "            plot_values_abs['gender'].append(gender)\n",
    "            plot_values_abs['topic'].append(topic)\n",
    "            plot_values_abs['counts'].append(val)\n",
    "            plot_values_abs['date'].append(f'{year}-{month:02}')\n",
    "            \n",
    "plot_values_abs = pd.DataFrame.from_dict(plot_values_abs)\n",
    "\n",
    "fig = px.bar(plot_values_abs,\n",
    "             x='topic',\n",
    "             y='counts',\n",
    "             color='gender',\n",
    "             title='Distribution of Genders per Key Topic',\n",
    "             animation_frame='date',\n",
    "             height=750,\n",
    "             range_y=[max(min(plot_values_abs['counts']),1), max(plot_values_abs['counts'])],\n",
    "             log_y = True,\n",
    "             barmode='group',\n",
    "             hover_name='gender',\n",
    "             hover_data={'gender':False, 'topic':False, 'counts':True, 'date':False},\n",
    "             )\n",
    "\n",
    "fig.update_layout(\n",
    "    #xaxis_title=\"Topic\",\n",
    "    yaxis_title=\"Word Counts by Gender per Topic\",\n",
    ")\n",
    "\n",
    "fig.write_html(\"./plotly/gender_in_topic.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b9e9a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb8af3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this part of our analysis we will be using the scores generated by the sentiment intensity analyzer of nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a590903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through years\n",
    "for year in years:\n",
    "    print(f\"Analysing year {year}...\", end=\" \")\n",
    "    \n",
    "    # data location\n",
    "    data_file = 'quotes-'+str(year)+'-prep.json.bz2'\n",
    "    data_path = data_folder + data_file\n",
    "    sent_analysis_folder = data_folder + 'sentiment_analysis/'\n",
    "    \n",
    "    # Load by chunks\n",
    "    f = bz2.open(data_path, \"rb\")\n",
    "    data=pd.read_json(f, lines=True, chunksize=10000)\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "    start_progress = timeit.default_timer()\n",
    "    progress_step = 100\n",
    "    \n",
    "    with bz2.open(sent_analysis_folder +str(year)+ '.json.bz2', \"w\") as fn:\n",
    "        for i_chunk, chunk in enumerate(data):\n",
    "            # Print progress\n",
    "            if i_chunk%progress_step == 0:\n",
    "                stop_progress = timeit.default_timer()\n",
    "                print(f'Time since last: {stop_progress-start_progress:.1f}s\\n')\n",
    "                print(f\"Processing chunks {i_chunk}-{i_chunk+progress_step-1}\")\n",
    "                start_progress = timeit.default_timer()\n",
    "                \n",
    "            # Process chunk\n",
    "            chunk.drop(columns=['probas','phase'], inplace=True)\n",
    "            chunk['sentiment_score']=chunk['quotation'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "            chunk['year']=chunk['date'].apply(lambda x: x.year)\n",
    "            chunk['month']=chunk['date'].apply(lambda x:x.month)\n",
    "            \n",
    "            # Write to json.bz2 file\n",
    "            write = chunk.to_json(fn, lines=True, orient='records')\n",
    "            \n",
    "    stop = timeit.default_timer()\n",
    "    print(f'Total time: {stop-start:.1f}s\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c20306b",
   "metadata": {},
   "source": [
    "In order to observe the differences between conservative and liberal news sources, to represent these two categories we have created 2 lists that contain some of the most popular liberal and conservative news sources according to ThoughtCo and Aelieve Digital Marketing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d4150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define lists of representative liberal and conservative news sources\n",
    "libr=['cnn', 'huffingtonpost', 'nytimes', 'politico', 'slate', 'abcnews', 'dailykos', 'washingtonpost', \n",
    "      'time', 'theatlantic']\n",
    "cons=['nationalreview', 'spectator', 'theamericanconservative', 'washingtontimes', 'thenewamerican', 'freebeacon',\n",
    "      'frontpagemag', 'theblaze', 'humanevents', 'cnsnews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0631e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Never ever run again\n",
    "\n",
    "df_repr=pd.DataFrame([])  #to keep only the representative websites in the list above\n",
    "df_sent=pd.DataFrame([])  #to keep the aggregated values\n",
    "\n",
    "# Loop through years\n",
    "for year in years:\n",
    "    print(f\"Analysing year {year}...\", end=\" \")\n",
    "    \n",
    "    # Load by chunks\n",
    "    f = bz2.open(sent_analysis_folder +str(year)+ '.json.bz2', \"rb\")\n",
    "    data=pd.read_json(f, lines=True, chunksize=10000)\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "    start_progress = timeit.default_timer()\n",
    "    progress_step = 100\n",
    "\n",
    "    for i_chunk, chunk in enumerate(data):\n",
    "        # Print progress\n",
    "        if i_chunk%progress_step == 0:\n",
    "            stop_progress = timeit.default_timer()\n",
    "            print(f'Time since last: {stop_progress-start_progress:.1f}s\\n')\n",
    "            print(f\"Processing chunks {i_chunk}-{i_chunk+progress_step-1}\")\n",
    "            start_progress = timeit.default_timer()\n",
    "            \n",
    "        # Process chunk\n",
    "        # aggregate over year-month-gender and save to df_sent\n",
    "        df_sent=df_sent.append(chunk.groupby(['year','month','gender']).agg({'sentiment_score':'mean', 'numOccurrences':'sum'}))\n",
    "        # keep only the quotes appeared in the representative lists\n",
    "        chunk=chunk[chunk['websites'].apply(lambda x: 1 if any(i in x for i in libr+cons) else 0)==1]\n",
    "        # explode each website list and drop the ones that are not in the lists\n",
    "        chunk=chunk.explode('websites')\n",
    "        chunk=chunk[chunk['websites'].isin(libr+cons)].drop_duplicates(['quoteID', 'quotation', 'speaker', 'date', 'numOccurrences', 'websites', 'gender', 'sentiment_score'])\n",
    "        df_repr=df_repr.append(chunk)\n",
    "                     \n",
    "    stop = timeit.default_timer()\n",
    "    print(f'Total time: {stop-start:.1f}s\\n')\n",
    "\n",
    "df_sent.reset_index(inplace=True)\n",
    "df_repr.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a79507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the representative data into json\n",
    "\n",
    "start = timeit.default_timer()\n",
    "start_progress = timeit.default_timer()\n",
    "progress_step = 100\n",
    "\n",
    "with bz2.open(sent_analysis_folder + 'representatives' + '.json.bz2', \"w\") as f:\n",
    "    for i in range(0, math.ceil(df_repr.shape[0]/10000)):\n",
    "        temp=df_repr[i*10000 : (i+1)*10000]\n",
    "        \n",
    "        # Print progress\n",
    "        stop_progress = timeit.default_timer()\n",
    "        print(f\"Saving rows {i*10000}-{(i+1)*10000}\")\n",
    "        print(f'Time since last: {stop_progress-start_progress:.1f}s\\n')\n",
    "        start_progress = timeit.default_timer()\n",
    "            \n",
    "        # Write to json.bz2 file\n",
    "        write = temp.to_json(f, lines=True, orient='records')\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print(f'Total time: {stop-start:.1f}s\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e00d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only the genders subject to analysis\n",
    "keep_gender_list=['male', 'female', 'transgender male', 'transgender female', 'non-binary', 'genderfluid']\n",
    "df_sent=df_sent[df_sent['gender'].isin(keep_gender_list)].reset_index(drop=True)\n",
    "df_repr=df_repr[df_repr['gender'].isin(keep_gender_list)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27efcc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary table of representative set and save \n",
    "df_repr_sum=df_repr.groupby(['year','month','gender', 'websites']).agg({'sentiment_score':'mean', 'quoteID':'count'}).reset_index()\n",
    "df_repr_sum.rename(columns={'quoteID': \"quoteID_count\"},inplace=True)\n",
    "\n",
    "with bz2.open(sent_analysis_folder + 'representatives_summary' + '.json.bz2', \"w\") as f:\n",
    "    write = df_repr_sum.to_json(f, lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001c2765",
   "metadata": {},
   "source": [
    "Since the aggregation of the overall summary table df_sent was done chunk by chunk, we need to correct it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2ce142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the aggregation in summary table, keep both sentiment_score and numOccurrences in the table final table\n",
    "\n",
    "df_sent2=df_sent.groupby(['year','month','gender']).apply(lambda x: (x['sentiment_score']*x['numOccurrences']).sum()/x['numOccurrences'].sum()).reset_index()\n",
    "temp=df_sent.groupby(['year','month','gender'])['numOccurrences'].agg('sum').reset_index()\n",
    "df_sent2=df_sent2.merge(temp, how='inner', on=['year','month','gender']) \n",
    "df_sent2.rename(columns={0: \"avg_sentiment_score\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb190317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combinde 'year'&'month'\n",
    "df_sent2['year']=df_sent2['year'].apply(str)\n",
    "df_sent2['month']=df_sent2['month'].apply(str)\n",
    "df_sent2['date']=df_sent2['year']+'-'+df_sent2['month']\n",
    "\n",
    "df_repr_sum['year']=df_repr_sum['year'].apply(str)\n",
    "df_repr_sum['month']=df_repr_sum['month'].apply(str)\n",
    "df_repr_sum['date']=df_repr_sum['year']+'-'+df_repr_sum['month']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d131ea",
   "metadata": {},
   "source": [
    "Let's see how the average sentiment scores have changed over the time for each gender category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c608a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.line(df_sent2, x=\"date\", y=\"avg_sentiment_score\", color='gender', \n",
    "              color_discrete_sequence=[\"#636EFA\", \"#EF553B\",  \"#00CC96\", \"#AB63FA\", \"#FFA15A\", \"#19D3F3\"],\n",
    "              category_orders={\"gender\":[\"male\", \"female\", \"transgender male\", \"transgender female\", \"non-binary\", \"genderfluid\"]}\n",
    "             )\n",
    "\n",
    "fig.update_layout(title_text='Average sentiment scores of quotes from different genders over time', title_x=0.5,\n",
    "                  xaxis_title='Date', yaxis_title='Average sentiment score', legend_title_text='Gender')\n",
    "\n",
    "fig.write_html('./plotly/sent_vs_time_allgenders_sep.html')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd72423",
   "metadata": {},
   "source": [
    "To be able to make more significant comparisons we combine transgender-male, transgender-female, genderfluid and non-binary genders in a single group named 'others' and plot the graph again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501636b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the others group and rearrange the summary table \n",
    "df_sent2['gender']=np.where(df_sent2['gender'].isin(['male','female']), df_sent2['gender'] ,'others')\n",
    "\n",
    "df_sent2_others=df_sent2.groupby(['year','month','gender','date']).apply(lambda x: (x['avg_sentiment_score']*x['numOccurrences']).sum()/x['numOccurrences'].sum()).reset_index()\n",
    "temp=df_sent2.groupby(['year','month','gender','date'])['numOccurrences'].agg('sum').reset_index()\n",
    "df_sent2_others=df_sent2_others.merge(temp, how='inner', on=['year','month','gender', 'date'])\n",
    "\n",
    "df_sent2_others.rename(columns={0: \"avg_sentiment_score\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b36bd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_sent2_others, x=\"date\", y=\"avg_sentiment_score\", color='gender', \n",
    "              color_discrete_sequence=[\"#636EFA\", \"#EF553B\",  \"#FF97FF\"],\n",
    "              category_orders={\"gender\":[\"male\", \"female\", \"others\"]}\n",
    "             )\n",
    "\n",
    "fig.update_layout(title_text='Average sentiment scores of quotes from different genders over time', title_x=0.5,\n",
    "                  xaxis_title='Date', yaxis_title='Average sentiment score', legend_title_text='Gender')\n",
    "\n",
    "fig.write_html('./plotly/sent_vs_time_allgenders.html')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d7344a",
   "metadata": {},
   "source": [
    "We can see that the average sentiment scores attached to male and female quotes lie between 0.15 and 0.26, which is close to neutral but still positive. On the other hand, quotes belonging to transgender-male, transgender-female, genderfluid and non-binary genders, which are aggregated in a single group named 'others', tend to have more oscillating average sentiment scores. For these genders, we can observe both positive and negative average scores that cover a wider range from -0.15 to 0.32. \n",
    "\n",
    "When we focus on quotes from males and females, we see that almost consistently scores of male quotes lie above the scores of female quotes. Whereas there is no such consistent pattern for other genders. Let's take a closer look into this consistent difference between male and female quotes.\n",
    "\n",
    "Let's see if this situation continues when we divide news sources into two categories as liberal and conservative. First, we make an overall comparison between liberal (denoted by L) and conservative (denoted by C) news sources, then take a deep dive into each website separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa06f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column specifying the class of the news source\n",
    "df_sent3=df_sent2[df_sent2['gender'].isin(['male','female'])]\n",
    "df_repr_sum2=df_repr_sum[df_repr_sum['gender'].isin(['male','female'])]\n",
    "df_repr_sum2['L/C']=df_repr_sum2['websites'].apply(lambda x: np.where(x in libr,'L','C'))\n",
    "\n",
    "#Aggregate on to the new column\n",
    "df_repr_sum3=df_repr_sum2.groupby(['year','month','gender','L/C']).apply(lambda x: (x['sentiment_score']*x['quoteID_count']).sum()/x['quoteID_count'].sum()).reset_index()\n",
    "temp=df_repr_sum2.groupby(['year','month','gender','L/C'])['quoteID_count'].agg('sum').reset_index()\n",
    "df_repr_sum3=df_repr_sum3.merge(temp, how='inner', on=['year','month','gender','L/C'])\n",
    "\n",
    "df_repr_sum3.rename(columns={0: \"avg_sentiment_score\"},inplace=True)\n",
    "\n",
    "#Combine year and month\n",
    "df_repr_sum3['year']=df_repr_sum3['year'].apply(str)\n",
    "df_repr_sum3['month']=df_repr_sum3['month'].apply(str)\n",
    "df_repr_sum3['date']=(df_repr_sum3['year']+'-'+df_repr_sum3['month'])\n",
    "df_repr_sum3['date']=pd.to_datetime(df_repr_sum3['date'], format='%Y-%m')\n",
    "df_repr_sum3.sort_values(by='date', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab818d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#Subsets for the subplots\n",
    "fm_l=df_repr_sum3[(df_repr_sum3['gender']=='female')&(df_repr_sum3['L/C']=='L')]\n",
    "fm_c=df_repr_sum3[(df_repr_sum3['gender']=='female')&(df_repr_sum3['L/C']=='C')]\n",
    "ml_l=df_repr_sum3[(df_repr_sum3['gender']=='male')&(df_repr_sum3['L/C']=='L')]\n",
    "ml_c=df_repr_sum3[(df_repr_sum3['gender']=='male')&(df_repr_sum3['L/C']=='C')]\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1, subplot_titles=(\"Liberal\", \"Conservative\"))\n",
    "\n",
    "fig.append_trace(go.Scatter(x=ml_l['date'], y=ml_l['avg_sentiment_score'], name='Male-L', marker={ 'color':'#636EFA'}), \n",
    "                 row=1, col=1)\n",
    "fig.append_trace(go.Scatter(x=fm_l['date'], y=fm_l['avg_sentiment_score'], name='Female-L', marker={ 'color':'#EF553B'}),\n",
    "                 row=1, col=1)\n",
    "fig.append_trace(go.Scatter(x=ml_c['date'], y=ml_c['avg_sentiment_score'], name='Male-C', marker={ 'color':'#636EFA'}),\n",
    "                 row=2, col=1)\n",
    "fig.append_trace(go.Scatter(x=fm_c['date'], y=fm_c['avg_sentiment_score'], name='Female-C', marker={ 'color':'#EF553B'}),\n",
    "                 row=2, col=1)\n",
    "\n",
    "fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Average sentiment score\")\n",
    "fig.update_layout(title_text=\"Average sentiment scores of quotes over time in liberal and conservative news sources\", title_x=0.5, \n",
    "                  legend_title_text='Gender')\n",
    "\n",
    "fig.write_html('./plotly/sent_vs_time_vs_lib&cons_male&female.html')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec26a341",
   "metadata": {},
   "source": [
    "From the plot above, we can see that in liberal news sources, sentiment scores of male and female quotes are close to each other, but the female quotes portrayed in these news sources have slightly higher positive scores compared to males'. On the other hand, in conservative news sources, we see that the gap between the male and female quotes' sentiment scores is a little wider compared to the gap in the liberal graph. Also, we can see that contrary to the quotes in liberal news sources, in conservative news sources the coverage given to male quotes have higher positive sentiment scores than the female quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24c8920",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_compare=fm_l.merge(ml_l, how='inner', on=['year','month','L/C'])\n",
    "c_compare=fm_c.merge(ml_c, how='inner', on=['year','month','L/C'])\n",
    "\n",
    "l_compare['diff']=l_compare['avg_sentiment_score_x']-l_compare['avg_sentiment_score_y']\n",
    "c_compare['diff']=c_compare['avg_sentiment_score_x']-c_compare['avg_sentiment_score_y']\n",
    "\n",
    "print('Mean female-male sentiment score diff in L: ', np.abs(l_compare['diff']).mean())\n",
    "print('Mean female-male sentiment score diff in C: ', np.abs(c_compare['diff']).mean())\n",
    "\n",
    "print('\\nFemale sent avg in L: ', fm_l['avg_sentiment_score'].mean())\n",
    "print('Female sent avg in C: ', fm_c['avg_sentiment_score'].mean())\n",
    "\n",
    "print('\\nMale sent avg in L: ', ml_l['avg_sentiment_score'].mean())\n",
    "print('Male sent avg in C: ', ml_c['avg_sentiment_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c7b5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Table(header=dict(values=['Mean of', 'Value']),\n",
    "                 cells=dict(values=[['Female-male quotes\\' sentiment score difference in L',\n",
    "                                     'Female-male quotes\\' sentiment score difference in C',\n",
    "                                     'Female quotes\\' sentiment score in L', \n",
    "                                     'Female quotes\\' sentiment score in C',\n",
    "                                     'Male quotes\\' sentiment score in L',\n",
    "                                     'Male quotes\\' sentiment score in C'], \n",
    "                                    [round(np.abs(l_compare['diff']).mean(),3), \n",
    "                                     round(np.abs(c_compare['diff']).mean(),3), \n",
    "                                     round(fm_l['avg_sentiment_score'].mean(),3), \n",
    "                                     round(fm_c['avg_sentiment_score'].mean(),3), \n",
    "                                     round(ml_l['avg_sentiment_score'].mean(),3),\n",
    "                                     round(ml_c['avg_sentiment_score'].mean(),3)]\n",
    "                                   ]\n",
    "                           )\n",
    "                              )\n",
    "                     ]\n",
    "               )\n",
    "fig.write_html(\"./plotly/mean_table.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62e2e77",
   "metadata": {},
   "source": [
    "This table shows that the mean difference between the average sentiment scores of female and male quotes in conservative news sources is twice of the liberal news sources. Also, we see that there is a 14% difference in the mean sentiment scores of female quotes in liberal and conservative news sources and a 38% difference for the male quotes. These results and the graphs above brings up two questions:\n",
    "\n",
    "**'Do the conservative news sources tend to give more coverage to quotes with higher positivity from males?'**\n",
    "\n",
    "**'Do the liberal news sources tend to give more coverage to quotes with higher positivity from females?'**\n",
    "\n",
    "Let's have a look at the distributions of the sentiment scores of quotes from males and females in liberal and conservative news sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7f3091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We go back to the summary table df_repr and divide it to 4 new tables:\n",
    "#female&liberal, female&conservative, male&liberal, male&conservative\n",
    "df_repr=df_repr[df_repr['gender'].isin(['female','male'])].reset_index(drop=True)\n",
    "df_repr['L/C']=df_repr['websites'].apply(lambda x: np.where(x in libr,'L','C'))\n",
    "\n",
    "df_repr_fm_l=df_repr[(df_repr['gender']=='female')&(df_repr['L/C']=='L')].reset_index()\n",
    "df_repr_fm_c=df_repr[(df_repr['gender']=='female')&(df_repr['L/C']=='C')].reset_index()\n",
    "\n",
    "df_repr_ml_l=df_repr[(df_repr['gender']=='male')&(df_repr['L/C']=='L')].reset_index()\n",
    "df_repr_ml_c=df_repr[(df_repr['gender']=='male')&(df_repr['L/C']=='C')].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b31c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Box(y=df_repr_ml_l['sentiment_score'], name='Male-Liberal', marker_color=\"#636EFA\"))\n",
    "fig.add_trace(go.Box(y=df_repr_ml_c['sentiment_score'], name='Male-Conservative', marker_color=\"#636EFA\"))\n",
    "fig.add_trace(go.Box(y=df_repr_fm_l['sentiment_score'], name='Female-Liberal', marker_color=\"#EF553B\"))\n",
    "fig.add_trace(go.Box(y=df_repr_fm_c['sentiment_score'], name='Female-Conservative', marker_color=\"#EF553B\"))\n",
    "\n",
    "\n",
    "fig.update_layout(title_text='Sentiment score distribution in liberal and conservative news sources ', title_x=0.5,\n",
    "                  xaxis_title='Gender & News Source', yaxis_title='Sentiment score', \n",
    "                  legend_title_text='Genders')\n",
    "fig.write_html(\"./plotly/box_sent_lib&cons_male&female.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688ec6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Var of male quotes in liberal news sources: ', df_repr_ml_l['sentiment_score'].var())\n",
    "print('Var of male quotes in conservative news sources: ', df_repr_ml_c['sentiment_score'].var())\n",
    "\n",
    "print('\\nVar of female quotes in liberal news sources: ', df_repr_fm_l['sentiment_score'].var())\n",
    "print('Var of female quotes in conservative news sources: ', df_repr_fm_c['sentiment_score'].var())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a23ef15",
   "metadata": {},
   "source": [
    "From the boxplot we can directly see that there is a general shift towards more positive sentiment scores of quotes belonging to men in conservative news sources. On the other side, we see that although the median and third quartile values of sentiment scores of female quotes are very similar in both liberal and conservative news sources, the first quartile value, which falls in the area of negative sentiment, is higher in the liberal news sources.\n",
    "\n",
    "Since the variance of the distributions are similar, to see if the differences we have seen in the sentiment scores with respect to news source category L/C in the sample we have created with the chosen news sources are significant for the whole population, we perform a one-sided independent student t-test with the following null hypotheses:\n",
    "\n",
    "    - Test 1 - H0: The mean sentiment score of quotes from males in conservative news sources is less than that of liberal \n",
    "    news sources.\n",
    "    - Test 2 - H0: The mean sentiment score of quotes from females in liberal news sources is less than that of conservative\n",
    "    news sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90192d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "#Student's t-test\n",
    "statistic, pvalue = stats.ttest_ind(df_repr_ml_c['sentiment_score'], df_repr_ml_l['sentiment_score'], alternative='greater')\n",
    "print(\"Student's t-test p-value for 'sentiment_score' of males' quotes in L and C: \" + str(pvalue/2))\n",
    "\n",
    "statistic2, pvalue2 = stats.ttest_ind(df_repr_fm_l['sentiment_score'], df_repr_fm_c['sentiment_score'], alternative='greater')\n",
    "print(\"Student's t-test p-value for 'sentiment_score' of females' quotes in L and C: \" + str(pvalue2/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b33bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Table(header=dict(values=['Test number', 'p-value/2']),\n",
    "                 cells=dict(values=[['Test - 1',\n",
    "                                     'Test - 2'], \n",
    "                                    [round(pvalue/2,5), \n",
    "                                     round(pvalue2/2,5)]\n",
    "                                   ]\n",
    "                           )\n",
    "                              )\n",
    "                     ]\n",
    "               )\n",
    "fig.write_html(\"./plotly/p_table.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d16c44d",
   "metadata": {},
   "source": [
    "Since for both tests, the p-values are less than the significance level threshold of 0.005, we have enough evidence to reject the null hypotheses and conclude that:\n",
    "\n",
    "    - The mean sentiment score of quotes from males portrayed in conservative news sources is higher than that of liberal \n",
    "      news sources. In other words, conservative news sources tend to give more coverage to quotes with higher positivity \n",
    "      from males compared to liberals\n",
    "    - The mean sentiment score of quotes from females portrayed in liberal news sources is greater than that of conservative \n",
    "      news sources. In other words, liberal news sources tend to give more coverage to quotes with higher positivity from \n",
    "      females compared to conservatives.\n",
    "\n",
    "Now that we had an overview of the sentiment score differences with respect to gender and news source category, let's have a closer look into the behavior of individual news sources within our representative news source lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eaad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "website_sum=df_repr.groupby(['websites','gender', 'L/C']).agg({'sentiment_score':'mean', 'quoteID':'count'}).reset_index()\n",
    "\n",
    "website_sum.rename(columns={'quoteID': \"quoteID_count\"},inplace=True)\n",
    "website_sum.rename(columns={'sentiment_score': \"avg_sentiment_score\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77154f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(website_sum[website_sum['L/C']=='L'], x = 'websites', y = 'avg_sentiment_score', \n",
    "                 size = 'quoteID_count', color = 'gender', size_max=50, \n",
    "                 color_discrete_map={\"male\": \"#636EFA\", \"female\": \"#EF553B\"},\n",
    "                 category_orders={\"gender\":[\"male\", \"female\"]})\n",
    "\n",
    "fig.update_layout(title = \"Sentiment scores in liberal news sources\", title_x=0.5,\n",
    "                  xaxis_title='News source websites', yaxis_title='Average sentiment score', legend_title_text='Gender')\n",
    "\n",
    "fig.write_html(\"./plotly/websites_L.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230cdb77",
   "metadata": {},
   "source": [
    "We can see that among the selected liberal news sources The New York Times is the one that portrays quotes with the most similar sentiment scores from males and females, followed by Slate, The Atlantic, Politico and CNN. Whereas Huffington Post is the one with the biggest difference in sentiment scores, followed by Time Magazine. We can also note that 9 out of 10 of the representative liberal news sources have quotes with higher sentiment scores from females, only 1 has a reversed trend, which is The Washington Post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84690fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(website_sum[website_sum['L/C']=='C'], x = 'websites', y = 'avg_sentiment_score', \n",
    "                 size = 'quoteID_count', color = 'gender',size_max=50, \n",
    "                 color_discrete_map={\"male\": \"#636EFA\", \"female\": \"#EF553B\"},\n",
    "                 category_orders={\"gender\":[\"male\", \"female\"]})\n",
    "\n",
    "fig.update_layout(title = \"Sentiment scores in conservative news sources\", title_x=0.5,\n",
    "                  xaxis_title='News source websites', yaxis_title='Average sentiment score', legend_title_text='Gender')\n",
    "\n",
    "fig.write_html(\"./plotly/websites_C.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687a43dd",
   "metadata": {},
   "source": [
    "We can see that among the selected conservative news sources National Review is the one that portrays quotes with the most similar sentiment scores from males and females, followed by The American Conservative, The American Spectator and The Blaze. Whereas Human Events and The Washington Times are the ones having the biggest difference in sentiment scores. The Washington Times also constitutes the majority of the quotes in the conservative group and therefore is an important factor in the trend towards more positive quotes from men in conservative news sources. By looking at the sizes of the data points in the graphs, in addition to the sentimental differences, we can see that conservative news sources make less use of quotations than liberal news sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb3ff43-63bd-4c4a-8c98-3df6f4a13318",
   "metadata": {},
   "source": [
    "# Text Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24e7517-179e-496a-95aa-8684328f691e",
   "metadata": {},
   "source": [
    "To measure the text complexity, the process is very similar all the other parts. We'll start by analyzing the data and extracting the relevant information, in this case the complexity information, per gender, per date, per website.\n",
    "\n",
    "These files are going to be saved in the `./data_processed` folder, under the names `complexity_<year>`. Furthermore, so we can do a more significant statistical analysis, we'll also save the standard deviation for all of these, in the files called `std_complexity_<year>`.\n",
    "\n",
    "The internal organization of these files is as follows. They separate the data by website, gender and date. So in each file we have one dictionary where the keys are the websites. In each entry we have another dictionary, where the keys are the genders. Finally, for each entry we have a list with 12 elements, one for each month, where we'll save the text complexity / standard deviation for that month. In short, if `root` is the root dictionary extracted from the folder, then to go all the way into it we need `root[website][gender][month]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df339ca-2ded-4e6d-8f55-89a12217e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the means\n",
    "from src.text_scores import *\n",
    "\n",
    "libr=['cnn', 'huffingtonpost', 'huffpost', 'nytimes', 'politico', 'slate', 'abcnews', 'dailykos', 'washingtonpost', 'time', 'theatlantic']\n",
    "cons=['nationalreview', 'spectator', 'theamericanconservative', 'washingtontimes', 'thenewamerican', 'freebeacon', 'frontpagemag', 'theblaze', 'humanevents', 'cnsnews']\n",
    "\n",
    "websites = libr + cons\n",
    "genders = ['male', 'female', 'transgender male', 'transgender female', 'non-binary', 'genderfluid']\n",
    "\n",
    "\n",
    "dfs_quotes = []\n",
    "for file in glob.glob(data_folder + data_file):\n",
    "    dfs_quotes.append(pd.read_json(file, lines=True, chunksize=1e4))\n",
    "\n",
    "start = timeit.default_timer()\n",
    "for year, file in enumerate(dfs_quotes):\n",
    "    complexity = {}\n",
    "    i = 0\n",
    "    for chunk in file:\n",
    "        tokens = {}\n",
    "        quotes = chunk['tokens'].tolist()\n",
    "        date = chunk['date'].tolist()\n",
    "        gender = chunk['gender'].tolist()\n",
    "        sources = chunk['websites'].tolist()\n",
    "        \n",
    "        for index, quote in enumerate(quotes):\n",
    "            if gender[index] not in genders:\n",
    "                continue\n",
    "            for source in sources[index]:\n",
    "                if source not in websites:\n",
    "                    continue\n",
    "                if source not in tokens.keys():\n",
    "                    tokens[source] = {}\n",
    "                if gender[index] not in tokens[source].keys():\n",
    "                    tokens[source][gender[index]] = [[] for _ in range(12)]\n",
    "                tokens[source][gender[index]][int(str(date[index])[5:7]) - 1].append(quote)\n",
    "        \n",
    "        for website in tokens.keys():\n",
    "            if website not in complexity.keys():\n",
    "                complexity[website] = {}\n",
    "            for gender in tokens[website].keys():\n",
    "                if gender not in complexity[website].keys():\n",
    "                    complexity[website][gender]= [[0,0] for _ in range(12)]\n",
    "                for month, quotes in enumerate(tokens[website][gender]):\n",
    "                    for quote in quotes:\n",
    "                        quote_join = ' '.join(quote)\n",
    "                        if len(quote_join) != 0:\n",
    "                            complexity[website][gender][month][0] += dale_chall_score(quote_join)\n",
    "                            complexity[website][gender][month][1] += 1\n",
    "\n",
    "        i += 1\n",
    "        if i % 10 == 0:\n",
    "            with open(f'complexity_{year + 2015}.txt', 'w') as f:\n",
    "                f.write(f'Chunks processed: {i}\\n')\n",
    "                f.write(json.dumps(complexity))\n",
    "            print(i, end = ',')\n",
    "\n",
    "            \n",
    "    # now we decompose the means\n",
    "    for website in complexity.keys():\n",
    "        for gender in complexity[website].keys():\n",
    "            for month, scores in enumerate(complexity[website][gender]):\n",
    "                if scores[1] != 0:\n",
    "                    complexity[website][gender][month] = scores[0] / scores[1]\n",
    "                else:\n",
    "                    complexity[website][gender][month] = 0\n",
    "    with open(f'complexity_{year + 2015}.txt', 'w') as f:\n",
    "        f.write(json.dumps(complexity))\n",
    "    print()\n",
    "\n",
    "\n",
    "print(f'Time to analyze all chunks {timeit.default_timer() - start}!!')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c7b62-cd1e-4d35-bd58-49b7e26dc11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the standard deviations\n",
    "from src.text_scores import *\n",
    "\n",
    "dfs_quotes = []\n",
    "for file in glob.glob(data_folder + data_file):\n",
    "    dfs_quotes.append(pd.read_json(file, lines=True, chunksize=1e4))\n",
    "\n",
    "complexity_means = []\n",
    "for file in glob.glob('./complexity*.txt'):\n",
    "    with open(file, 'r') as f:\n",
    "        complexity_means.append(eval(f.read()))\n",
    "\n",
    "        \n",
    "start = timeit.default_timer()\n",
    "for year, file in enumerate(dfs_quotes):\n",
    "    complexity_std = {}\n",
    "    i = 0\n",
    "    for chunk in file:\n",
    "        tokens = {}\n",
    "        quotes = chunk['tokens'].tolist()\n",
    "        date = chunk['date'].tolist()\n",
    "        gender = chunk['gender'].tolist()\n",
    "        sources = chunk['websites'].tolist()\n",
    "        \n",
    "        for index, quote in enumerate(quotes):\n",
    "            if gender[index] not in genders:\n",
    "                continue\n",
    "            for source in sources[index]:\n",
    "                if source not in websites:\n",
    "                    continue\n",
    "                if source not in tokens.keys():\n",
    "                    tokens[source] = {}\n",
    "                if gender[index] not in tokens[source].keys():\n",
    "                    tokens[source][gender[index]] = [[] for _ in range(12)]\n",
    "                tokens[source][gender[index]][int(str(date[index])[5:7]) - 1].append(quote)\n",
    "        \n",
    "        for website in tokens.keys():\n",
    "            if website not in complexity_std.keys():\n",
    "                complexity_std[website] = {}\n",
    "            for gender in tokens[website].keys():\n",
    "                if gender not in complexity_std[website].keys():\n",
    "                    complexity_std[website][gender]= [[0,0] for _ in range(12)]\n",
    "                for month, quotes in enumerate(tokens[website][gender]):\n",
    "                    # print('sgmi', website, gender, month, i)\n",
    "                    for quote in quotes:\n",
    "                        quote_join = ' '.join(quote)\n",
    "                        if len(quote_join) != 0:\n",
    "                            complexity_std[website][gender][month][0] += (dale_chall_score(quote_join) - complexity_means[year][website][gender][month])**2\n",
    "                            complexity_std[website][gender][month][1] += 1\n",
    "\n",
    "        i += 1\n",
    "        if i % 10 == 0:\n",
    "            with open(f'std_complexity_{year + 2015}.txt', 'w') as f:\n",
    "                f.write(f'Chunks processed: {i}\\n')\n",
    "                f.write(json.dumps(complexity_std))\n",
    "            print(i, end = ',')\n",
    "\n",
    "    # now we decompose the means\n",
    "    for website in complexity_std.keys():\n",
    "        for gender in complexity_std[website].keys():\n",
    "            for month, scores in enumerate(complexity_std[website][gender]):\n",
    "                if scores[1] == 0 or scores[1] == 1:\n",
    "                    complexity_std[website][gender][month] = 0\n",
    "                else:\n",
    "                    complexity_std[website][gender][month] = np.sqrt(scores[0] / (scores[1] * (scores[1] - 1)))\n",
    "    with open(f'std_complexity_{year + 2015}.txt', 'w') as f:\n",
    "        f.write(json.dumps(complexity_std))\n",
    "    print()\n",
    "\n",
    "\n",
    "print(f'Time to analyze all chunks {timeit.default_timer() - start}!!')        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e391e995-9184-4280-9103-7fd145e641b6",
   "metadata": {},
   "source": [
    "After all the data has already been processed, we just need to access it in the save files, which is much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440f59f7-91ac-44c0-adc4-de6d0e240cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "complexity_data_files = glob.glob('./data_processed/complexity*.txt')\n",
    "complexity_std_files  = glob.glob('./data_processed/std_*.txt')\n",
    "\n",
    "complexity_data = []\n",
    "complexity_std  = []\n",
    "\n",
    "for file in complexity_data_files:\n",
    "    with open(file, 'r') as f:\n",
    "        txt = f.read()\n",
    "        complexity_data.append(eval(txt))\n",
    "        \n",
    "for file in complexity_std_files:\n",
    "    with open(file, 'r') as f:\n",
    "        txt = f.read()\n",
    "        complexity_std.append(eval(txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b3e7dd-fac8-4fa1-9e2d-5cd8e029c062",
   "metadata": {},
   "source": [
    "Next we save it into a DataFrame, because `plotly` handles information much more easily if it comes in a DataFrame. Besides, we're much more interested in the differences of complexity between men and women, so that's what we'll keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddd7f8f-4a74-4c0c-90d8-52e5a2df85de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's sort all of this into a dataframe\n",
    "clean_data = {'date': [],\n",
    "              'gender': [],\n",
    "              'website': [],\n",
    "              'complexity': [],\n",
    "              'std': []\n",
    "             }\n",
    "\n",
    "for year, data in enumerate(complexity_data):\n",
    "    for website in data.keys():\n",
    "        for gender in data[website].keys():\n",
    "            for month, complexity in enumerate(data[website][gender]):\n",
    "                if complexity > 1:\n",
    "                    clean_data['date'].append(f\"{month + 1:02}-{year + 2015}\")\n",
    "                    clean_data['gender'].append(gender)\n",
    "                    clean_data['website'].append(website)\n",
    "                    clean_data['complexity'].append(float(complexity))\n",
    "                    clean_data['std'].append(complexity_std[year][website][gender][month])\n",
    "                                \n",
    "df = pd.DataFrame.from_dict(clean_data)\n",
    "print(df)\n",
    "\n",
    "df_diff = {'date': [],\n",
    "           'website': [],\n",
    "           'diff_comp': [],\n",
    "           'diff_std': [],\n",
    "           'male': [],\n",
    "           'female': []\n",
    "          }\n",
    "\n",
    "for date in df['date'].unique():\n",
    "    for website in df['website'].unique():\n",
    "        try:\n",
    "            male = df[(df['date'] == date) & (df['website'] == website) & (df['gender'] == 'male')]\n",
    "            female = df[(df['date'] == date) & (df['website'] == website) & (df['gender'] == 'female')]\n",
    "            diff_data = male['complexity'].values[0] - female['complexity'].values[0]\n",
    "            diff_std  = np.sqrt(male['std'].values[0]**2 + female['std'].values[0]**2)\n",
    "            \n",
    "            df_diff['date'].append(date)\n",
    "            df_diff['website'].append(website)\n",
    "            df_diff['diff_comp'].append(diff_data)\n",
    "            df_diff['diff_std'].append(diff_std)\n",
    "            df_diff['male'].append(male['complexity'].values[0])\n",
    "            df_diff['female'].append(female['complexity'].values[0])\n",
    "        except:\n",
    "            pass\n",
    "df_diff = pd.DataFrame.from_dict(df_diff)\n",
    "display(df_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f380c035-635e-45bf-b044-5a1c87488b3c",
   "metadata": {},
   "source": [
    "Since we're not particularly interested in a temporal analysis of the complexity, we'll cluster all the temporal data, keeping only the division into websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bda860-1ccb-49ff-a519-4c2ac3a7a668",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff['count'] = df_diff['website']\n",
    "df_grouped = df_diff.groupby(['website'], as_index=False).agg({\n",
    "    'diff_comp' : np.mean,\n",
    "    'diff_std': np.std,\n",
    "    'count': np.size,\n",
    "    'male': np.mean,\n",
    "    'female': np.mean\n",
    "})\n",
    "\n",
    "df_grouped['diff_std'] /= np.sqrt(df_grouped['count'])\n",
    "df_grouped = df_grouped.drop(['count'], axis=1)\n",
    "\n",
    "display(df_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe7459a-ce6e-4931-b54f-6ef0e6c28cba",
   "metadata": {},
   "source": [
    "Finally, we divide into liberal and conservative newspapers and plot the two graphs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea945b47-ecbe-4a69-a3e8-1982fb425ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "libr=['cnn', 'huffingtonpost', 'huffpost', 'nytimes', 'politico', 'slate', 'abcnews', 'dailykos', 'washingtonpost', 'time', 'theatlantic']\n",
    "cons=['nationalreview', 'spectator', 'theamericanconservative', 'washingtontimes', 'thenewamerican', 'freebeacon', 'frontpagemag', 'theblaze', 'humanevents', 'cnsnews']\n",
    "\n",
    "df_libr = df_grouped[df_grouped['website'].isin(libr)]\n",
    "df_cons = df_grouped[df_grouped['website'].isin(cons)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b8e5c3-13e5-4323-a1c0-f2cbaa3e17af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is for showing the gender distribution for any topic\n",
    "# this cell will be for the overall topic evolution\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# we prepare our data for plotting\n",
    "fig = px.bar(df_libr,\n",
    "             x='website',\n",
    "             y='diff_comp',\n",
    "             title='Difference Of Text Complexity (Men - Women) on Liberal Websites',\n",
    "             width=750,\n",
    "             error_y = 'diff_std',\n",
    "             hover_name = 'website',\n",
    "             hover_data={'male':True, 'female': True, 'website':False,'diff_comp':True}\n",
    "             )\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Website\",\n",
    "    yaxis_title=\"Complexity Men - Complexity Women\",\n",
    "    xaxis={'categoryorder':'total descending'}\n",
    ")\n",
    "\n",
    "fig.write_html(\"./plotly/text_complexity_libr.html\")\n",
    "\n",
    "fig = px.bar(df_cons,\n",
    "             x='website',\n",
    "             y='diff_comp',\n",
    "             title='Difference Of Text Complexity (Men - Women) on Conservative Websites',\n",
    "             width=750,\n",
    "             error_y = 'diff_std',\n",
    "             hover_name = 'website',\n",
    "             hover_data={'male':True, 'female': True, 'website':False,'diff_comp':True}\n",
    "             )\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Website\",\n",
    "    yaxis_title=\"Complexity Men - Complexity Women\",\n",
    "    xaxis={'categoryorder':'total descending'}\n",
    ")\n",
    "\n",
    "fig.write_html(\"./plotly/text_complexity_cons.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268fd637-514d-4cab-8bd1-a58b9fb5e0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
