The tuned hyperparameters were found by a grid search, ran on a random sample of 50000 quotes for men and 50000 for women. The parameters changed in the grid search were number of topics ({1, 10 (DEFAULT), 25, 50, 75, 100}) and document-topic prior ({1, 1/sqrt(number_topics), 1/number_topics (DEFAULT), 1/number_topics**2}) for both men and women. The Learning Decay was left as the default parameter. The metric used to decide the best hyperparameters was Topic Coherence (calculated via u_mass).

After this first search, a finer grid was used, with number of topics varying in {8, 10, 12, 15, 20} and document-topic prior in {0.1, 1, 10} (already now only constants because as we saw the constants gave better results). This lead to the following hyperparameters.

Male Quotes:
    Number of Topics : 10
    Document-Topic Prior : 1
    Learning Decay : 0.7 (Default)
Female Quotes:
    Number of Topics : 12
    Document-Topic Prior : 0.1
    Learning-Decay : 0.7 (Default)